# ğŸ¯ Arquitetura de Prompts - RAG Lab

## PrincÃ­pio de Design

**COMPARAÃ‡ÃƒO JUSTA**: Todas as tÃ©cnicas RAG usam o **MESMO prompt de resposta final**.

Apenas o **mÃ©todo de retrieval** (como os documentos sÃ£o buscados) muda entre tÃ©cnicas.

---

## ğŸ“Š Arquitetura Visual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ANSWER_PROMPT (UNIVERSAL)                     â”‚
â”‚                                                                   â”‚
â”‚  Voce e um assistente especializado em responder perguntas       â”‚
â”‚  baseado APENAS no contexto fornecido.                           â”‚
â”‚                                                                   â”‚
â”‚  CONTEXTO: {context}                                             â”‚
â”‚  PERGUNTA: {query}                                               â”‚
â”‚                                                                   â”‚
â”‚  INSTRUCOES:                                                     â”‚
â”‚  1. Responda usando APENAS as informacoes do contexto            â”‚
â”‚  2. Se nao souber, diga que nao encontrou informacoes            â”‚
â”‚  3. Seja preciso e objetivo                                      â”‚
â”‚  4. Cite trechos relevantes                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ USADO POR TODAS AS 4 TÃ‰CNICAS
                                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚                         â”‚
        â–¼                         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BASELINE    â”‚      â”‚      HYDE        â”‚      â”‚    RERANKING     â”‚
â”‚               â”‚      â”‚                  â”‚      â”‚                  â”‚
â”‚ 1. Embed queryâ”‚      â”‚ 1. Gerar doc hip.â”‚      â”‚ 1. Busca inicial â”‚
â”‚ 2. Search     â”‚      â”‚    (prompt esp.) â”‚      â”‚ 2. Rerank Cohere â”‚
â”‚ 3. Get docs   â”‚      â”‚ 2. Search c/ doc â”‚      â”‚ 3. Filter top-N  â”‚
â”‚               â”‚      â”‚ 3. Get docs      â”‚      â”‚                  â”‚
â”‚ â†“             â”‚      â”‚ â†“                â”‚      â”‚ â†“                â”‚
â”‚ ANSWER_PROMPT â”‚      â”‚ ANSWER_PROMPT    â”‚      â”‚ ANSWER_PROMPT    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     AGENTIC      â”‚
                        â”‚                  â”‚
                        â”‚ 1. Planejar      â”‚
                        â”‚    (prompt esp.) â”‚
                        â”‚ 2. Multi-busca   â”‚
                        â”‚ 3. Combine docs  â”‚
                        â”‚ â†“                â”‚
                        â”‚ ANSWER_PROMPT    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Componentes do Sistema

### 1ï¸âƒ£ ANSWER_PROMPT (Universal)
**Arquivo**: `core/prompts.py`

```python
ANSWER_PROMPT = PromptTemplate(
    input_variables=["context", "query"],
    template="""..."""  # Mesmo para TODAS as tÃ©cnicas
)
```

**Usado por**:
- âœ… Baseline RAG
- âœ… HyDE RAG
- âœ… Reranking RAG
- âœ… Agentic RAG

**Garantia**: `verify_prompts_identical()` valida na importaÃ§Ã£o

---

### 2ï¸âƒ£ Prompts EspecÃ­ficos de TÃ©cnicas

**HYDE_GENERATE_DOC** (apenas HyDE):
```python
# Etapa intermediÃ¡ria: gerar documento hipotÃ©tico
HYDE_GENERATE_DOC = PromptTemplate(
    input_variables=["query"],
    template="Gere um documento hipotetico..."
)
```

**AGENTIC_PLANNER** (apenas Agentic):
```python
# Etapa intermediÃ¡ria: planejar busca
AGENTIC_PLANNER = PromptTemplate(
    input_variables=["query"],
    template="Analise a pergunta e crie um plano..."
)
```

---

## ğŸ”„ Fluxo de Cada TÃ©cnica

### Baseline RAG
```
Query do usuÃ¡rio
    â†“
1. Embed query
2. Search Pinecone (top_k=5)
3. Get documents
    â†“
ANSWER_PROMPT.format(context=docs, query=query)
    â†“
LLM gera resposta
```

### HyDE RAG
```
Query do usuÃ¡rio
    â†“
1. HYDE_GENERATE_DOC.format(query=query)
2. LLM gera documento hipotÃ©tico
3. Embed documento hipotÃ©tico
4. Search Pinecone com embedding do doc
5. Get documents reais
    â†“
ANSWER_PROMPT.format(context=docs, query=query)  â† MESMO PROMPT!
    â†“
LLM gera resposta
```

### Reranking RAG
```
Query do usuÃ¡rio
    â†“
1. Embed query
2. Search Pinecone (top_k=20, mais docs)
3. Get documents
4. Rerank com Cohere (top_k=5)
5. Filter top-N documentos
    â†“
ANSWER_PROMPT.format(context=docs, query=query)  â† MESMO PROMPT!
    â†“
LLM gera resposta
```

### Agentic RAG
```
Query do usuÃ¡rio
    â†“
1. AGENTIC_PLANNER.format(query=query)
2. LLM gera plano de busca
3. MÃºltiplas buscas baseadas no plano
4. Combine documentos de todas as buscas
    â†“
ANSWER_PROMPT.format(context=docs, query=query)  â† MESMO PROMPT!
    â†“
LLM gera resposta
```

---

## âœ… Garantias de ComparaÃ§Ã£o Justa

### O que Ã© IDÃŠNTICO entre tÃ©cnicas:
- âœ… Prompt de geraÃ§Ã£o final (`ANSWER_PROMPT`)
- âœ… LLM usado (Gemini 2.0 Flash)
- âœ… Temperature
- âœ… Max tokens
- âœ… Formato da resposta

### O que DIFERE entre tÃ©cnicas:
- âŒ **MÃ©todo de busca** (embedding, HyDE, reranking, agentic)
- âŒ **NÃºmero de documentos** intermediÃ¡rios
- âŒ **Processamento dos documentos** (filtragem, reordenaÃ§Ã£o)

---

## ğŸ“ API de Uso

### Para Implementadores de TÃ©cnicas:

```python
from core.prompts import get_answer_prompt

async def minha_tecnica_rag(query: str, top_k: int = 5):
    # 1. Recuperar documentos (mÃ©todo especÃ­fico da tÃ©cnica)
    docs = await meu_metodo_de_busca(query, top_k)

    # 2. Preparar contexto
    context = "\n\n".join([doc.page_content for doc in docs])

    # 3. Usar ANSWER_PROMPT universal (SEMPRE!)
    answer_prompt = get_answer_prompt()
    prompt = answer_prompt.format(context=context, query=query)

    # 4. Gerar resposta
    llm = get_llm()
    response = llm.invoke(prompt)

    return response.content
```

### Para HyDE (com etapa intermediÃ¡ria):

```python
from core.prompts import get_hyde_doc_generator, get_answer_prompt

async def hyde_rag(query: str, top_k: int = 5):
    # Etapa 1: Gerar documento hipotÃ©tico (ESPECÃFICO DO HYDE)
    doc_gen_prompt = get_hyde_doc_generator()
    hyp_doc_prompt = doc_gen_prompt.format(query=query)
    hyp_doc = llm.invoke(hyp_doc_prompt).content

    # Etapa 2: Buscar com documento hipotÃ©tico
    docs = vector_store.search(hyp_doc, k=top_k)

    # Etapa 3: Responder (MESMO PROMPT DAS OUTRAS!)
    context = "\n\n".join([doc.page_content for doc in docs])
    answer_prompt = get_answer_prompt('hyde')  # Retorna ANSWER_PROMPT
    prompt = answer_prompt.format(context=context, query=query)
    response = llm.invoke(prompt)

    return response.content
```

---

## ğŸ§ª ValidaÃ§Ã£o

### Teste AutomÃ¡tico:

```python
from core.prompts import verify_prompts_identical, get_prompt_info

# Executado automaticamente na importaÃ§Ã£o
verify_prompts_identical()  # LanÃ§a AssertionError se nÃ£o forem iguais

# Ver informaÃ§Ãµes do sistema
info = get_prompt_info()
print(info)
# {
#     'universal_prompt': True,
#     'techniques': ['baseline', 'hyde', 'reranking', 'agentic'],
#     'prompts_identical': True,
#     'design_principle': 'Todas as tÃ©cnicas usam o MESMO prompt...'
# }
```

### Teste Manual:

```python
from core.prompts import get_answer_prompt

# Verificar que todas retornam o mesmo objeto
baseline_prompt = get_answer_prompt('baseline')
hyde_prompt = get_answer_prompt('hyde')
reranking_prompt = get_answer_prompt('reranking')
agentic_prompt = get_answer_prompt('agentic')

assert baseline_prompt is hyde_prompt is reranking_prompt is agentic_prompt
print("âœ… Todos os prompts sÃ£o idÃªnticos!")
```

---

## ğŸ“Š MÃ©tricas de ComparaÃ§Ã£o

Com prompts idÃªnticos, as diferenÃ§as nas mÃ©tricas vÃªm **APENAS** da tÃ©cnica de retrieval:

| MÃ©trica | O que compara |
|---------|---------------|
| **Latency** | Tempo de execuÃ§Ã£o de cada tÃ©cnica |
| **Faithfulness** | Fidelidade ao contexto recuperado |
| **Answer Relevancy** | RelevÃ¢ncia da resposta Ã  pergunta |
| **Context Precision** | PrecisÃ£o dos documentos recuperados |
| **Context Recall** | Recall dos documentos recuperados |
| **Cost** | Custo em tokens (variaÃ§Ãµes devido a contextos diferentes) |

---

## ğŸš€ BenefÃ­cios

### Para Pesquisadores:
- âœ… ComparaÃ§Ã£o cientÃ­fica vÃ¡lida
- âœ… Resultados reproduzÃ­veis
- âœ… Isolamento de variÃ¡veis

### Para Desenvolvedores:
- âœ… Prompt centralizado
- âœ… FÃ¡cil modificaÃ§Ã£o (muda 1 lugar, afeta todas)
- âœ… ValidaÃ§Ã£o automÃ¡tica

### Para UsuÃ¡rios:
- âœ… ComparaÃ§Ã£o justa entre tÃ©cnicas
- âœ… ConfianÃ§a nos resultados
- âœ… Escolha baseada em dados reais

---

## ğŸ”§ Modificando o Prompt Universal

**IMPORTANTE**: Se modificar `ANSWER_PROMPT`, afeta TODAS as tÃ©cnicas.

```python
# core/prompts.py

# âŒ ERRADO: Criar prompt diferente para cada tÃ©cnica
BASELINE_PROMPT = PromptTemplate(...)
HYDE_PROMPT = PromptTemplate(...)  # DIFERENTE!

# âœ… CERTO: Um prompt Ãºnico para todas
ANSWER_PROMPT = PromptTemplate(...)
TECHNIQUE_ANSWER_PROMPTS = {
    "baseline": ANSWER_PROMPT,  # Mesmo objeto
    "hyde": ANSWER_PROMPT,      # Mesmo objeto
    "reranking": ANSWER_PROMPT, # Mesmo objeto
    "agentic": ANSWER_PROMPT,   # Mesmo objeto
}
```

---

## ğŸ“š ReferÃªncias

- **LangChain PromptTemplate**: https://python.langchain.com/docs/modules/model_io/prompts/
- **RAG Evaluation**: https://docs.ragas.io/
- **Scientific Method**: Controle de variÃ¡veis em experimentos

---

**Criado**: 2024
**Projeto**: RAG Lab Backend
**VersÃ£o**: 1.0.0
