# Fusion - CombinaÃ§Ã£o de MÃºltiplas EstratÃ©gias de Retrieval

## ğŸ“‹ DefiniÃ§Ã£o

**Fusion** (tambÃ©m chamado de **RAG Fusion** ou **Hybrid Retrieval**) Ã© uma meta-tÃ©cnica que **combina resultados de mÃºltiplas estratÃ©gias de busca diferentes** para maximizar tanto recall quanto precision.

A ideia Ã© que diferentes mÃ©todos de busca capturam aspectos complementares da relevÃ¢ncia.

**Insight**: Nenhuma tÃ©cnica Ã© perfeita. Combinar vÃ¡rias tÃ©cnicas cancela fraquezas e amplifica forÃ§as.

---

## ğŸ”„ Como Funciona

### Pipeline Completo

```
1. QUERY AUGMENTATION (PreparaÃ§Ã£o)
   â”œâ”€ Query original: "Qual o lucro Q3?"
   â”œâ”€ Gerar variaÃ§Ãµes da query:
   â”‚  â”œâ”€ VariaÃ§Ã£o 1: Original
   â”‚  â”œâ”€ VariaÃ§Ã£o 2: Reformulada (LLM)
   â”‚  â”œâ”€ VariaÃ§Ã£o 3: Com sinÃ´nimos
   â”‚  â””â”€ VariaÃ§Ã£o 4: Mais especÃ­fica
   â””â”€ Total: 3-5 variaÃ§Ãµes

2. MULTI-STRATEGY RETRIEVAL (Busca Paralela)
   â”œâ”€ Para cada variaÃ§Ã£o, executar:
   â”‚  â”œâ”€ Busca SemÃ¢ntica (Vector DB)
   â”‚  â”œâ”€ Busca Lexical (BM25/Keyword)
   â”‚  â””â”€ Busca HÃ­brida (Semantic + Lexical)
   â””â”€ Resultado: MÃºltiplos conjuntos de chunks

3. FUSION (CombinaÃ§Ã£o) â­
   â”œâ”€ Reciprocal Rank Fusion (RRF)
   â”‚  â””â”€ Score = Î£ 1/(k + rank_in_list_i)
   â”œâ”€ Combinar rankings de todas estratÃ©gias
   â””â”€ Reordenar chunks por score final

4. GERAÃ‡ÃƒO
   â”œâ”€ Selecionar top-k chunks fusionados
   â”œâ”€ Montar prompt
   â””â”€ LLM gera resposta
```

### ComparaÃ§Ã£o Visual

**Baseline RAG:**
```
Query â†’ Busca SemÃ¢ntica â†’ 5 chunks
```

**Fusion:**
```
Query
  â†“ [Gera variaÃ§Ãµes]
Q1, Q2, Q3
  â†“ [MÃºltiplas estratÃ©gias]
Q1 â†’ SemÃ¢ntica â†’ 10 chunks
Q1 â†’ Lexical  â†’ 10 chunks
Q2 â†’ SemÃ¢ntica â†’ 10 chunks
Q2 â†’ Lexical  â†’ 10 chunks
Q3 â†’ SemÃ¢ntica â†’ 10 chunks
  â†“ [FusÃ£o RRF]
50 chunks â†’ Dedup â†’ RRF â†’ Top 10
```

---

## ğŸ’¡ Por Que Funciona?

### Complementaridade de EstratÃ©gias

**Busca SemÃ¢ntica (Vector):**
- âœ… Captura sinÃ´nimos e contexto
- âœ… Entende intenÃ§Ã£o semÃ¢ntica
- âŒ Falha em keywords exatos
- âŒ SensÃ­vel a vocabulÃ¡rio

**Busca Lexical (BM25):**
- âœ… Match exato de keywords
- âœ… Funciona com nomes prÃ³prios
- âŒ NÃ£o entende sinÃ´nimos
- âŒ NÃ£o captura contexto

**FusÃ£o = Melhor dos Dois Mundos:**
```python
Query: "CEO da Apple"

# SemÃ¢ntica:
Chunk 1: "Tim Cook lidera a Apple..."        Score: 0.92 âœ…
Chunk 2: "Diretor executivo da Apple..."     Score: 0.85 âœ… (sinÃ´nimo)

# Lexical (BM25):
Chunk 1: "CEO Apple: Tim Cook..."            Score: 0.95 âœ… (keyword exato)
Chunk 3: "Apple CEO anunciou..."             Score: 0.88 âœ…

# Fusion (RRF):
Chunk 1: Alta em AMBAS â†’ RRF = 0.98 â­ (melhor)
Chunk 2: Alta em semÃ¢ntica â†’ RRF = 0.75
Chunk 3: Alta em lexical â†’ RRF = 0.72

# âœ… Chunk 1 (que aparece bem em ambas) ganha
```

---

## ğŸ”¬ Exemplo PrÃ¡tico Detalhado

### Caso 1: Query com Nome PrÃ³prio

**Query:**
```
"PolÃ­tica de trabalho remoto da empresa XYZ Corp"
```

**SemÃ¢ntica Sozinha (Perde Nome):**
```python
# Embedding captura "polÃ­tica trabalho remoto"
# Mas pode nÃ£o priorizar "XYZ Corp" especificamente

Chunks:
1. "PolÃ­tica remoto: 3 dias/semana..." (genÃ©rico)    0.88
2. "XYZ Corp permite trabalho flexÃ­vel..."           0.75 (baixo!)
3. "Trabalho remoto em empresas tech..."             0.82
```

**Lexical Sozinha (Perde Contexto):**
```python
# BM25 busca keywords "XYZ Corp" "trabalho remoto"

Chunks:
1. "XYZ Corp sede localizada..."                     0.90 (tem "XYZ" mas nÃ£o Ã© polÃ­tica)
2. "XYZ Corp permite trabalho flexÃ­vel..."           0.85 âœ…
3. "PolÃ­tica remoto na empresa ABC..."               0.70 (nÃ£o Ã© XYZ)
```

**Fusion (Combina ForÃ§as):**
```python
# RRF combina rankings:

Chunk "XYZ Corp permite trabalho flexÃ­vel...":
  - SemÃ¢ntica: Rank 2 â†’ 1/(60+2) = 0.016
  - Lexical:   Rank 1 â†’ 1/(60+1) = 0.016
  - RRF = 0.032 â­ (soma = melhor score)

Chunk "PolÃ­tica remoto: 3 dias/semana...":
  - SemÃ¢ntica: Rank 1 â†’ 1/(60+1) = 0.016
  - Lexical:   Rank 5 â†’ 1/(60+5) = 0.015
  - RRF = 0.031

# âœ… Chunk correto (XYZ + remoto) vence!
```

---

### Caso 2: Query Variations Power

**Query Original:**
```
"Como melhorar performance do sistema?"
```

**VariaÃ§Ãµes Geradas:**
```
V1: "Como melhorar performance do sistema?"          (original)
V2: "OtimizaÃ§Ã£o de desempenho de aplicaÃ§Ãµes"         (reformulada)
V3: "Reduzir latÃªncia e aumentar throughput"         (especÃ­fica)
V4: "Melhorar velocidade processamento sistema"      (sinÃ´nimos)
```

**Resultado:**
```python
# Cada variaÃ§Ã£o captura chunks diferentes:

V1 â†’ "Performance sistema: cache Redis..."           âœ…
V2 â†’ "OtimizaÃ§Ã£o aplicaÃ§Ãµes: indexaÃ§Ã£o DB..."        âœ…
V3 â†’ "Reduzir latÃªncia: CDN e compressÃ£o..."         âœ…
V4 â†’ "Velocidade: paralelizaÃ§Ã£o processos..."        âœ…

# FusÃ£o garante cobertura completa de todas perspectivas
# Recall massivo: 0.50 â†’ 0.90
```

---

## âš™ï¸ ConfiguraÃ§Ã£o PadrÃ£o

| ParÃ¢metro | Valor | Justificativa |
|-----------|-------|---------------|
| **Query Variations** | 3-4 | Balance recall vs latÃªncia |
| **Retrieval Strategies** | 2 (Semantic + BM25) | Complementares |
| **Top-K per Strategy** | 10 | Captura diversidade |
| **Fusion Method** | RRF (k=60) | PadrÃ£o da literatura |
| **Final Top-K** | 10 | Suficiente para LLM |
| **Deduplication** | Sim | Remove duplicatas |

### EstratÃ©gias de Retrieval Comuns

| EstratÃ©gia | MÃ©todo | Uso |
|------------|--------|-----|
| **Semantic** | Vector DB (embeddings) | Contexto, sinÃ´nimos |
| **Lexical** | BM25, TF-IDF | Keywords exatas |
| **Hybrid** | Weighted combination | Balance |
| **HyDE** | Hypothetical embeddings | Queries abertas |
| **Multi-Query** | Query variations | Cobertura |

---

## âœ… Vantagens

### 1. Recall + Precision SimultÃ¢neos
```
Baseline:
- Alta precision OU alto recall (nÃ£o ambos)

Fusion:
- Recall: 0.85-0.95 (query variations)
- Precision: 0.85-0.90 (RRF filtra ruÃ­do)
```

### 2. Robustez a Diferentes Queries
```
âœ… Queries com keywords â†’ Lexical ajuda
âœ… Queries semÃ¢nticas â†’ Vector ajuda
âœ… Queries mistas â†’ Fusion equilibra
```

### 3. Cancela Fraquezas Individuais
```
Semantic falha em keyword exato
â†’ Lexical compensa

Lexical falha em sinÃ´nimos
â†’ Semantic compensa

Fusion = Safety net
```

### 4. Escalabilidade de EstratÃ©gias
```python
# Adicionar novas estratÃ©gias facilmente:
strategies = [
    semantic_search,
    bm25_search,
    hyde_search,
    graph_search,
    custom_search
]

# Fusion combina TODAS automaticamente
```

### 5. State-of-the-Art Results
```
BEIR benchmark: Fusion = top 3 tÃ©cnicas
Melhor que qualquer tÃ©cnica individual
```

---

## âŒ Desvantagens

### 1. LatÃªncia Extrema
```
Baseline: 1.2s
Fusion: 3.5-6.0s

Breakdown:
- 4 query variations: +0.8s (LLM)
- 2 strategies Ã— 4 queries = 8 buscas: +2.0s
- Fusion (RRF): +0.5s
- GeraÃ§Ã£o: 1.2s

Total: 4-6 segundos
```

### 2. Custo Massivo
```
# LLM calls:
1. Gerar query variations (4x)
2. GeraÃ§Ã£o final
Total: 5 LLM calls vs 1 baseline

# Vector DB:
8 buscas vs 1 baseline

Custo: $0.010-0.020 por query (+500-1000%!)
```

### 3. Complexidade ImplementaÃ§Ã£o
```
Precisa implementar/integrar:
- Vector DB (Pinecone)
- BM25 engine (Elasticsearch ou local)
- Query variation generator
- RRF algorithm
- Deduplication logic

Complexidade operacional alta
```

### 4. DeduplicaÃ§Ã£o Imperfeita
```
Mesmo chunk pode aparecer em mÃºltiplas buscas:

Busca 1: "Lucro Q3 foi R$ 3bi..."
Busca 2: "Lucro Q3 foi R$ 3 bi..." (formataÃ§Ã£o diferente)

âŒ Dedup por hash falha (texto diferente)
â†’ Chunks duplicados inflam context window
```

### 5. RRF Pode NÃ£o Ser Ã“timo
```
RRF assume todas estratÃ©gias tÃªm peso igual

Mas:
- Semantic pode ser 2x melhor que BM25
- Deveria ter peso maior

Weighted fusion resolve, mas precisa tuning
```

### 6. NÃ£o Funciona Para Queries Simples
```
Query: "Telefone"

âŒ Query variations inÃºteis:
- "Telefone"
- "NÃºmero de telefone"
- "Contato telefÃ´nico"

âŒ MÃºltiplas estratÃ©gias retornam mesmo chunk
â†’ Overhead sem benefÃ­cio
```

---

## ğŸ“Š MÃ©tricas Esperadas

### RAGAS Scores vs Baseline

| MÃ©trica | Baseline | Fusion | Î” |
|---------|----------|--------|---|
| **Faithfulness** | 0.75-0.85 | 0.85-0.92 | +10-15% |
| **Answer Relevancy** | 0.70-0.85 | 0.88-0.95 | +20-25% |
| **Context Precision** | 0.60-0.75 | 0.85-0.92 | +30-40% |
| **Context Recall** | 0.50-0.70 | 0.85-0.95 | +50-70% â­ |

### Performance

| MÃ©trica | Baseline | Fusion |
|---------|----------|--------|
| **LatÃªncia** | 1.2-2.5s | 3.5-6.5s |
| **Custo/Query** | $0.001-0.003 | $0.010-0.025 |
| **Chunks Retrieved** | 5 | 15-25 (deduplicated) |
| **Throughput** | ~40 q/min | ~10-15 q/min |

---

## ğŸ¯ Quando Usar Fusion

### âœ… Casos Ideais

**1. MÃ¡xima Qualidade NecessÃ¡ria**
```
âœ… Research assistants (academia)
âœ… Legal/compliance (zero margem erro)
âœ… Medical diagnosis support
```

**2. Queries Diversas e ImprevisÃ­veis**
```
âœ… Chat geral (nÃ£o sabe tipo de query)
âœ… Multi-domain knowledge base
âœ… User queries em linguagem natural variada
```

**3. Benchmark e CompetiÃ§Ãµes**
```
âœ… Comparar com state-of-the-art
âœ… Demonstrar capabilities
âœ… Provar viabilidade tÃ©cnica
```

**4. Baixo Volume, Alta Criticidade**
```
âœ… <1K queries/dia
âœ… Budget OK com $10-20/dia
âœ… Cada resposta vale muito (decisÃµes crÃ­ticas)
```

**5. Cobrir MÃºltiplas Modalidades**
```
âœ… CÃ³digo + documentaÃ§Ã£o + logs
âœ… Dados estruturados + texto livre
âœ… Multi-idioma
```

---

### âŒ Quando NÃƒO Usar

**1. ProduÃ§Ã£o em Escala**
```
âŒ >10K queries/dia
âŒ Custo seria $200-500/dia
âŒ LatÃªncia 5s inaceitÃ¡vel para UX
```

**2. Queries Simples e PrevisÃ­veis**
```
âŒ FAQ system (queries repetitivas)
âŒ Lookup database (queries diretas)
â†’ Baseline 5x mais rÃ¡pido e barato
```

**3. Budget Limitado**
```
âŒ Custo 10x baseline
âŒ Startups early-stage
â†’ Use tÃ©cnicas individuais otimizadas
```

**4. LatÃªncia CrÃ­tica**
```
âŒ Real-time chat (<2s)
âŒ Autocomplete (<500ms)
âŒ API com SLA <1s
```

**5. Infraestrutura Simples**
```
âŒ SÃ³ tem Vector DB (sem BM25)
âŒ NÃ£o quer manter mÃºltiplos sistemas
â†’ Use Reranking ou HyDE
```

---

## ğŸ”¬ Experimentos Recomendados

### 1. Strategy Combination Testing
```python
# Testar combinaÃ§Ãµes:
# - Semantic only
# - Semantic + BM25
# - Semantic + BM25 + HyDE
# - Todas estratÃ©gias

# Medir: Recall vs LatÃªncia vs Custo
```

### 2. Query Variation Count
```python
# Testar: 1, 2, 3, 5, 10 variations
# Medir: Recall improvement vs LatÃªncia
# HipÃ³tese: 3-4 variations = sweet spot
```

### 3. Fusion Algorithm Comparison
```python
# Testar:
# - Simple voting (count)
# - RRF (reciprocal rank)
# - Weighted fusion (tuned weights)
# - Learned fusion (ML model)

# Medir: Precision + Recall
```

### 4. Top-K Optimization
```python
# Per strategy: Testar k=5, 10, 20, 50
# Final: Testar k=5, 10, 15, 20
# Medir: Recall vs Context Window size
```

---

## ğŸ’» Estrutura de CÃ³digo

```python
# fusion.py

import numpy as np
from rank_bm25 import BM25Okapi
from typing import List, Dict

class FusionRAG:
    """
    RAG Fusion: Combina mÃºltiplas estratÃ©gias de retrieval.

    Pipeline:
    1. Query variations
    2. Multi-strategy retrieval
    3. Reciprocal Rank Fusion
    4. LLM generation
    """

    def __init__(self, pinecone_index, embeddings, llm, bm25_corpus=None):
        self.index = pinecone_index
        self.embeddings = embeddings
        self.llm = llm

        # BM25 para busca lexical
        self.bm25 = None
        if bm25_corpus:
            self.bm25 = BM25Okapi(bm25_corpus)

        self.num_variations = 3
        self.k_per_strategy = 10

    def generate_query_variations(self, query: str) -> List[str]:
        """
        Gera variaÃ§Ãµes da query para aumentar recall.
        """
        prompt = f"""
Gere 3 variaÃ§Ãµes diferentes da query abaixo.
Cada variaÃ§Ã£o deve:
- Usar sinÃ´nimos e reformulaÃ§Ãµes
- Manter a intenÃ§Ã£o original
- Ser mais especÃ­fica ou usar termos tÃ©cnicos

Query original: "{query}"

Retorne apenas as 3 variaÃ§Ãµes, uma por linha:
"""
        response = self.llm.invoke(prompt, temperature=0.7)

        variations = [query]  # Incluir original
        variations.extend([
            v.strip()
            for v in response.content.split('\n')
            if v.strip() and not v.strip().startswith('#')
        ][:3])

        return variations

    def semantic_search(self, query: str, k: int) -> List[Document]:
        """
        Busca semÃ¢ntica (vector DB).
        """
        query_vector = self.embeddings.embed_query(query)

        results = self.index.query(
            vector=query_vector,
            top_k=k,
            include_metadata=True
        )

        chunks = self._parse_results(results)

        # Marcar estratÃ©gia
        for chunk in chunks:
            chunk.metadata['strategy'] = 'semantic'

        return chunks

    def lexical_search(self, query: str, k: int) -> List[Document]:
        """
        Busca lexical (BM25).
        """
        if not self.bm25:
            return []

        # Tokenizar query
        query_tokens = query.lower().split()

        # BM25 scores
        scores = self.bm25.get_scores(query_tokens)

        # Top-k indices
        top_indices = np.argsort(scores)[::-1][:k]

        chunks = [self.corpus_docs[i] for i in top_indices]

        # Marcar estratÃ©gia
        for chunk, score in zip(chunks, scores[top_indices]):
            chunk.metadata['strategy'] = 'lexical'
            chunk.metadata['bm25_score'] = float(score)

        return chunks

    def multi_strategy_retrieval(
        self,
        query_variations: List[str]
    ) -> List[List[Document]]:
        """
        Executa mÃºltiplas estratÃ©gias para cada variaÃ§Ã£o.
        """
        all_results = []

        for query_var in query_variations:
            # Semantic
            semantic_chunks = self.semantic_search(query_var, self.k_per_strategy)
            all_results.append(semantic_chunks)

            # Lexical
            if self.bm25:
                lexical_chunks = self.lexical_search(query_var, self.k_per_strategy)
                all_results.append(lexical_chunks)

        return all_results

    def reciprocal_rank_fusion(
        self,
        ranked_lists: List[List[Document]],
        k: int = 60
    ) -> List[Document]:
        """
        FusÃ£o usando Reciprocal Rank Fusion.

        RRF(d) = Î£ 1/(k + rank(d) in list_i)
        """
        # Coletar todos chunks Ãºnicos
        all_chunks = []
        for ranked_list in ranked_lists:
            all_chunks.extend(ranked_list)

        # Deduplicar por conteÃºdo
        unique_chunks = {}
        for chunk in all_chunks:
            content_hash = hash(chunk.page_content)
            if content_hash not in unique_chunks:
                unique_chunks[content_hash] = chunk

        # Calcular RRF score para cada chunk Ãºnico
        rrf_scores = {}

        for content_hash, chunk in unique_chunks.items():
            score = 0.0

            # Somar contribuiÃ§Ã£o de cada ranked list
            for ranked_list in ranked_lists:
                try:
                    # Encontrar posiÃ§Ã£o deste chunk nesta lista
                    for rank, c in enumerate(ranked_list):
                        if hash(c.page_content) == content_hash:
                            score += 1.0 / (k + rank)
                            break
                except:
                    pass

            rrf_scores[content_hash] = score
            chunk.metadata['rrf_score'] = score

        # Ordenar por RRF score
        sorted_chunks = sorted(
            unique_chunks.values(),
            key=lambda x: x.metadata['rrf_score'],
            reverse=True
        )

        return sorted_chunks

    def generate(self, query: str, context: List[Document]) -> str:
        """
        GeraÃ§Ã£o com LLM.
        """
        prompt = self._build_prompt(query, context)
        response = self.llm.invoke(prompt, temperature=0.0)
        return response.content

    def query(self, query: str) -> Dict:
        """
        Pipeline completo Fusion RAG.
        """
        start_time = time.time()

        # 1. Query variations
        t1 = time.time()
        variations = self.generate_query_variations(query)
        variation_time = time.time() - t1

        # 2. Multi-strategy retrieval
        t2 = time.time()
        ranked_lists = self.multi_strategy_retrieval(variations)
        retrieval_time = time.time() - t2

        # 3. Fusion (RRF)
        t3 = time.time()
        fused_chunks = self.reciprocal_rank_fusion(ranked_lists)
        fusion_time = time.time() - t3

        # Selecionar top-10 finais
        final_chunks = fused_chunks[:10]

        # 4. GeraÃ§Ã£o
        t4 = time.time()
        response = self.generate(query, final_chunks)
        generation_time = time.time() - t4

        total_latency = time.time() - start_time

        return {
            "response": response,
            "chunks": final_chunks,
            "query_variations": variations,
            "metrics": {
                "latency_total": total_latency,
                "latency_variations": variation_time,
                "latency_retrieval": retrieval_time,
                "latency_fusion": fusion_time,
                "latency_generation": generation_time,
                "num_variations": len(variations),
                "num_strategies": len(ranked_lists),
                "chunks_total": sum(len(rl) for rl in ranked_lists),
                "chunks_unique": len(fused_chunks),
                "chunks_final": len(final_chunks),
                "technique": "fusion"
            }
        }
```

---

## ğŸ“ VariaÃ§Ãµes AvanÃ§adas

### 1. Weighted Fusion
```python
def weighted_fusion(ranked_lists, weights):
    """
    FusÃ£o com pesos por estratÃ©gia.

    weights = [0.6, 0.4]  # Semantic 60%, BM25 40%
    """
    for chunk in all_chunks:
        score = 0.0
        for i, ranked_list in enumerate(ranked_lists):
            rank = ranked_list.index(chunk)
            score += weights[i] * (1.0 / (60 + rank))

        chunk.metadata['weighted_score'] = score

    return sorted(chunks, key=lambda x: x.metadata['weighted_score'], reverse=True)
```

---

### 2. Learned Fusion
```python
from sklearn.ensemble import RandomForestClassifier

def learned_fusion(ranked_lists, training_data):
    """
    Aprende weights automaticamente.
    """
    # Features: [semantic_rank, bm25_rank, semantic_score, bm25_score]
    X_train, y_train = prepare_training_data(training_data)

    # Treinar classificador de relevÃ¢ncia
    model = RandomForestClassifier()
    model.fit(X_train, y_train)

    # Predizer relevÃ¢ncia para cada chunk
    for chunk in all_chunks:
        features = extract_features(chunk, ranked_lists)
        relevance = model.predict_proba([features])[0][1]
        chunk.metadata['learned_score'] = relevance

    return sorted(chunks, key=lambda x: x.metadata['learned_score'], reverse=True)
```

---

### 3. Ensemble com Todas TÃ©cnicas
```python
def ultimate_fusion(query):
    """
    Combina TODAS tÃ©cnicas RAG.
    """
    # Gerar variaÃ§Ãµes
    variations = generate_variations(query)

    # MÃºltiplas estratÃ©gias
    results = []
    for var in variations:
        results.append(baseline_rag(var))
        results.append(hyde_rag(var))
        results.append(semantic_search(var))
        results.append(bm25_search(var))

    # Fusion
    fused = reciprocal_rank_fusion(results)

    # Reranking final
    final = rerank(query, fused[:50], k=10)

    return final
```

**Resultado**: Precision 0.95, Recall 0.95 (mas 10s latÃªncia, $0.05/query)

---

## ğŸ“š ReferÃªncias

**Papers:**
- Cormack et al. (2009) - "Reciprocal Rank Fusion outperforms Condorcet and individual rank learning methods"
- Sarto et al. (2023) - "Retrieval-Augmented Generation with Multiple Rankings"

**ImplementaÃ§Ãµes:**
- LangChain: `EnsembleRetriever`
- Weaviate: Hybrid search (alpha parameter)

**Benchmarks:**
- BEIR: RRF fusion = +8% nDCG@10 vs best single method
- TREC: Consistent improvements across all datasets

---

## ğŸ¯ Aprendizados Chave

1. **Ensemble > Individual**: Fusion sempre supera tÃ©cnica individual
2. **RRF Ã© Robusto**: Funciona bem sem tuning, ao contrÃ¡rio de weighted fusion
3. **Query Variations = Recall Booster**: 3-4 variations ideal
4. **Trade-off Extremo**: Melhor qualidade, pior latÃªncia/custo
5. **Production Reality**: Ã“timo para benchmark, difÃ­cil para escala

---

## ğŸ“ˆ ProgressÃ£o de Complexidade

```
Baseline RAG
    â†“
Fusion (vocÃª estÃ¡ aqui) = Meta-tÃ©cnica
    â†“
    â”œâ”€â†’ Weighted Fusion (tuned)
    â”œâ”€â†’ Learned Fusion (ML)
    â””â”€â†’ Ultimate Ensemble (ALL techniques)
```

---

**TÃ©cnica Anterior**: [Sub-Query](./SUBQUERY.md)
**PrÃ³xima TÃ©cnica**: [Graph RAG](./GRAPH_RAG.md)
