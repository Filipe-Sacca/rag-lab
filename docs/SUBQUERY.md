# Sub-Query Decomposition - DecomposiÃ§Ã£o de Queries Complexas

## ğŸ“‹ DefiniÃ§Ã£o

**Sub-Query Decomposition** Ã© uma tÃ©cnica que **quebra queries complexas em mÃºltiplas sub-queries simples**, executa buscas independentes para cada uma, e depois **combina os resultados**.

Resolve o problema de queries que exigem informaÃ§Ã£o de mÃºltiplos contextos ou documentos diferentes.

**Insight**: Uma query complexa = vÃ¡rias queries simples. Buscar separadamente aumenta recall.

---

## ğŸ”„ Como Funciona

### Pipeline Completo

```
1. DECOMPOSIÃ‡ÃƒO (Novo!)
   â”œâ”€ Query complexa: "Compare lucro Q3 com investimento em marketing"
   â”œâ”€ LLM decompÃµe em sub-queries:
   â”‚  â”œâ”€ Sub-query 1: "Qual foi o lucro do Q3?"
   â”‚  â”œâ”€ Sub-query 2: "Qual foi o investimento em marketing no Q3?"
   â”‚  â””â”€ Sub-query 3: "RelaÃ§Ã£o entre lucro e marketing"
   â””â”€ Retornar lista de sub-queries

2. RETRIEVAL PARALELO
   â”œâ”€ Para cada sub-query:
   â”‚  â”œâ”€ Gerar embedding
   â”‚  â”œâ”€ Buscar no Pinecone (top-k por sub-query)
   â”‚  â””â”€ Armazenar chunks
   â””â”€ Combinar todos chunks (deduplicaÃ§Ã£o)

3. FUSÃƒO (Opcional)
   â”œâ”€ Reciprocal Rank Fusion (RRF)
   â”œâ”€ Reordenar chunks combinados
   â””â”€ Selecionar top-k final

4. GERAÃ‡ÃƒO
   â”œâ”€ Montar prompt com chunks de TODAS sub-queries
   â”œâ”€ LLM sintetiza resposta completa
   â””â”€ Retornar resposta final
```

### ComparaÃ§Ã£o Visual

**Baseline RAG:**
```
Query complexa â†’ Busca Ãºnica â†’ 5 chunks (incompletos)
```

**Sub-Query:**
```
Query complexa
    â†“ [DecompÃµe]
Sub-query 1 â†’ Busca â†’ 5 chunks
Sub-query 2 â†’ Busca â†’ 5 chunks
Sub-query 3 â†’ Busca â†’ 5 chunks
    â†“ [Combina]
15 chunks â†’ Deduplica/Fusiona â†’ 10 chunks finais
```

---

## ğŸ’¡ Por Que Funciona?

### Problema do Baseline

```python
Query: "Compare lucro Q3 com investimento em marketing e analise ROI"

# Embedding da query (mistura 3 conceitos):
query_vector = embed("Compare lucro Q3 com investimento marketing analise ROI")

# Busca retorna (confuso):
Chunk 1: "Lucro Q3: R$ 3bi..."              âœ… (parcial)
Chunk 2: "Marketing digital cresceu..."      âœ… (parcial)
Chunk 3: "EstratÃ©gia de marketing..."        âŒ (genÃ©rico)
Chunk 4: "ROI de investimentos gerais..."    âŒ (nÃ£o especÃ­fico)
Chunk 5: "Resultado financeiro Q3..."        âœ… (parcial)

# âŒ Nenhum chunk tem informaÃ§Ã£o completa
# âŒ Falta chunk especÃ­fico sobre "investimento marketing Q3"
```

### SoluÃ§Ã£o Sub-Query

```python
# LLM decompÃµe:
sub_queries = [
    "Qual foi o lucro do terceiro trimestre?",
    "Qual foi o investimento em marketing no terceiro trimestre?",
    "Como calcular ROI de marketing?"
]

# Busca 1 (foco: lucro):
chunks_1 = search("lucro terceiro trimestre", k=5)
â†’ "Lucro Q3: R$ 3bi, crescimento 15%..."     âœ…

# Busca 2 (foco: marketing):
chunks_2 = search("investimento marketing terceiro trimestre", k=5)
â†’ "Investimento marketing Q3: R$ 500mi..."   âœ…

# Busca 3 (foco: ROI):
chunks_3 = search("calcular ROI marketing", k=5)
â†’ "ROI = (Receita - Custo) / Custo..."       âœ…

# Combina todos chunks:
final_chunks = deduplicate(chunks_1 + chunks_2 + chunks_3)
â†’ 12 chunks Ãºnicos, TODOS relevantes

# âœ… InformaÃ§Ã£o completa para resposta
```

**Resultado**: Context Recall de 0.50 â†’ 0.85

---

## ğŸ”¬ Exemplo PrÃ¡tico Detalhado

### Caso 1: Query Multi-Hop

**Query:**
```
"Quem Ã© o CFO e qual sua experiÃªncia anterior em finanÃ§as?"
```

**Baseline (Falha):**
```python
# Busca Ãºnica com query completa
results = search("CFO experiÃªncia anterior finanÃ§as")

# Chunks recuperados (incompletos):
1. "Nosso CFO Ã© JoÃ£o Silva..."               âœ… (nome)
2. "Equipe de lideranÃ§a inclui CFO..."       âŒ (genÃ©rico)
3. "ExperiÃªncia em finanÃ§as corporativas..." âŒ (nÃ£o vincula ao CFO)
4. "JoÃ£o Silva foi promovido..."             âŒ (nÃ£o menciona experiÃªncia)

# âŒ Tem o nome, mas nÃ£o tem a experiÃªncia dele
```

**Sub-Query (Sucesso):**
```python
# DecomposiÃ§Ã£o:
sub_1 = "Quem Ã© o CFO da empresa?"
sub_2 = "Qual a experiÃªncia anterior do CFO?"

# Busca 1 (identifica pessoa):
chunks_1 = search(sub_1, k=5)
â†’ "CFO: JoÃ£o Silva, formado em Harvard..."   âœ…

# Busca 2 (com contexto de "CFO"):
chunks_2 = search(sub_2, k=5)
â†’ "JoÃ£o Silva trabalhou 10 anos no Goldman Sachs..." âœ…

# LLM sintetiza:
"O CFO Ã© JoÃ£o Silva. Ele possui 10 anos de experiÃªncia
 no Goldman Sachs antes de se juntar Ã  empresa."

# âœ… Resposta completa conectando ambas as informaÃ§Ãµes
```

---

### Caso 2: ComparaÃ§Ã£o Entre Entidades

**Query:**
```
"Compare o desempenho de vendas de 2023 vs 2024"
```

**Baseline (Incompleto):**
```python
results = search("vendas 2023 vs 2024")

# Chunks (podem nÃ£o ter ambos os anos):
1. "Vendas 2024: R$ 10mi, crescimento..."    âœ… (2024)
2. "Performance de vendas melhorou..."       âŒ (vago)
3. "Vendas 2023: R$ 8mi..."                  âœ… (2023)

# âŒ Tem dados, mas nÃ£o focados na comparaÃ§Ã£o
```

**Sub-Query (Completo):**
```python
sub_1 = "Qual foi o desempenho de vendas em 2023?"
sub_2 = "Qual foi o desempenho de vendas em 2024?"
sub_3 = "Qual a diferenÃ§a percentual entre vendas 2023 e 2024?"

# Busca focada por ano:
chunks_1 = search(sub_1, k=3)  # SÃ³ 2023
chunks_2 = search(sub_2, k=3)  # SÃ³ 2024
chunks_3 = search(sub_3, k=3)  # AnÃ¡lise comparativa

# Resultado: Dados completos de ambos perÃ­odos + anÃ¡lise
```

---

## âš™ï¸ ConfiguraÃ§Ã£o PadrÃ£o

| ParÃ¢metro | Valor | Justificativa |
|-----------|-------|---------------|
| **Max Sub-Queries** | 3-5 | Balance entre recall e latÃªncia |
| **Top-K per Sub-Query** | 3-5 | Evita explosÃ£o de chunks |
| **Deduplication** | Sim | Remove chunks duplicados |
| **Fusion Method** | RRF | Combina rankings de forma justa |
| **LLM (Decomposition)** | Gemini 2.5 Flash | RÃ¡pido para decomposiÃ§Ã£o |
| **Temperature** | 0.0 | DecomposiÃ§Ã£o determinÃ­stica |

---

## âœ… Vantagens

### 1. Recall Massivo
```
Baseline: 1 busca â†’ 5 chunks â†’ Recall 0.50
Sub-Query: 3 buscas â†’ 15 chunks â†’ Recall 0.85 (+70%)
```

### 2. Queries Multi-Hop Resolvidas
```
âœ… "Quem Ã© X e qual sua posiÃ§Ã£o em Y?"
âœ… "Compare A com B em termos de C"
âœ… "Relacione evento X com impacto em Y"
```

### 3. Cobertura de MÃºltiplos Documentos
```
Query complexa pode precisar:
- Doc financeiro (lucro)
- Doc marketing (investimento)
- Doc estratÃ©gico (anÃ¡lise)

Sub-queries garantem busca em TODOS
```

### 4. PrecisÃ£o por Contexto
```
Cada sub-query Ã© simples e focada:
â†’ Embedding mais preciso
â†’ Busca mais direcionada
â†’ Menos ruÃ­do
```

### 5. TransparÃªncia e Debug
```
Pode ver exatamente:
- Quais sub-queries foram geradas
- Que chunks cada uma retornou
- Como foram combinados

Facilita identificar falhas
```

---

## âŒ Desvantagens

### 1. LatÃªncia Alta
```
Baseline: 1 busca = 1.2s
Sub-Query: 3 buscas = 2.5-4.0s

Breakdown:
- DecomposiÃ§Ã£o: +0.5s (LLM)
- 3x buscas: +1.0s (paralelo) ou +2.0s (sequencial)
- FusÃ£o: +0.3s
- GeraÃ§Ã£o: 1.0s
```

### 2. Custo Elevado
```
# Chamadas LLM:
1. DecomposiÃ§Ã£o (gerar sub-queries)
2. GeraÃ§Ã£o final (resposta)

# Buscas vetoriais:
3x buscas no Pinecone (vs 1x baseline)

Custo: $0.004-0.008 por query (+200-300%)
```

### 3. Risco de Over-Decomposition
```
Query simples: "Qual o telefone?"

âŒ LLM pode decompor desnecessariamente:
- "NÃºmero de telefone da empresa"
- "CÃ³digo de Ã¡rea do telefone"
- "Tipo de telefone (fixo/mÃ³vel)"

â†’ Overhead sem benefÃ­cio
```

### 4. CombinaÃ§Ã£o Complexa
```
15 chunks de 3 sub-queries:
- Como priorizar?
- Como evitar informaÃ§Ã£o conflitante?
- Qual chunk Ã© mais importante?

Fusion (RRF) ajuda, mas nÃ£o Ã© perfeito
```

### 5. Context Window Explodir
```
3 sub-queries Ã— 5 chunks = 15 chunks
15 chunks Ã— 512 tokens = 7,680 tokens

Se chunk size = 1024:
15 Ã— 1024 = 15,360 tokens (pode exceder limite LLM!)

Precisa limitar top-k ou comprimir chunks
```

### 6. DependÃªncia de DecomposiÃ§Ã£o
```
Se LLM decompÃµe MAL:
âŒ Sub-queries irrelevantes
âŒ Perde aspecto importante da query original
âŒ Busca em direÃ§Ã£o errada

Qualidade da decomposiÃ§Ã£o = crÃ­tica
```

---

## ğŸ“Š MÃ©tricas Esperadas

### RAGAS Scores vs Baseline

| MÃ©trica | Baseline | Sub-Query | Î” |
|---------|----------|-----------|---|
| **Faithfulness** | 0.75-0.85 | 0.80-0.88 | +5-10% |
| **Answer Relevancy** | 0.70-0.85 | 0.75-0.90 | +5-15% |
| **Context Precision** | 0.60-0.75 | 0.65-0.80 | +5-10% |
| **Context Recall** | 0.50-0.70 | 0.75-0.90 | +40-60% â­ |

### Performance

| MÃ©trica | Baseline | Sub-Query |
|---------|----------|-----------|
| **LatÃªncia** | 1.2-2.5s | 2.5-4.5s |
| **Custo/Query** | $0.001-0.003 | $0.004-0.010 |
| **Chunks Retrieved** | 5 | 10-15 (deduplicated) |
| **Throughput** | ~40 q/min | ~15-20 q/min |

---

## ğŸ¯ Quando Usar Sub-Query

### âœ… Casos Ideais

**1. Queries Multi-Hop**
```
âœ… "Quem Ã© o CEO e qual sua formaÃ§Ã£o acadÃªmica?"
âœ… "Produto X foi lanÃ§ado quando e quais foram as vendas?"
âœ… "Relacione evento A com impacto em B"
```

**2. ComparaÃ§Ãµes**
```
âœ… "Compare vendas 2023 vs 2024"
âœ… "DiferenÃ§a entre plano bÃ¡sico e premium"
âœ… "Produto A vs Produto B: qual melhor?"
```

**3. AgregaÃ§Ã£o de MÃºltiplos Contextos**
```
âœ… "AnÃ¡lise completa: financeiro + operacional + estratÃ©gico"
âœ… "Resumo de todos departamentos sobre projeto X"
```

**4. Queries com MÃºltiplas Partes**
```
âœ… "PolÃ­tica de fÃ©rias, benefÃ­cios E processo de avaliaÃ§Ã£o"
âœ… "PreÃ§o, especificaÃ§Ãµes tÃ©cnicas E disponibilidade do produto"
```

**5. AnÃ¡lises Complexas**
```
âœ… "Impacto do investimento em P&D no crescimento de receita"
âœ… "CorrelaÃ§Ã£o entre satisfaÃ§Ã£o do cliente e retenÃ§Ã£o"
```

---

### âŒ Quando NÃƒO Usar

**1. Queries Simples e Diretas**
```
âŒ "Qual o telefone?"
âŒ "Email do suporte"
âŒ "HorÃ¡rio de funcionamento"
â†’ Baseline Ã© suficiente e 2x mais rÃ¡pido
```

**2. Lookup Factual**
```
âŒ "PreÃ§o do produto X"
âŒ "Data de lanÃ§amento"
â†’ NÃ£o precisa de mÃºltiplas buscas
```

**3. LatÃªncia CrÃ­tica**
```
âŒ Requisitos de <2s resposta
âŒ Chatbot em tempo real
â†’ Sub-Query pode levar 4-5s
```

**4. Vector DB Pequeno**
```
âŒ <1K documentos
â†’ Busca Ãºnica jÃ¡ cobre tudo
â†’ Sub-queries = overhead desnecessÃ¡rio
```

**5. Budget Apertado**
```
âŒ Custo 3x do baseline
âŒ Alto volume de queries (>50K/dia)
â†’ Pode ficar caro rapidamente
```

---

## ğŸ”¬ Experimentos Recomendados

### 1. Number of Sub-Queries
```python
# Testar: 2, 3, 5, 7 sub-queries
# Medir: Recall vs LatÃªncia
# HipÃ³tese: 3-4 sub-queries = sweet spot
```

### 2. Top-K per Sub-Query
```python
# Testar: k=3, k=5, k=10 por sub-query
# Medir: Recall vs Context Window overflow
# HipÃ³tese: k=3-5 balanceia cobertura e tokens
```

### 3. Fusion Method Comparison
```python
# Testar:
# - Simple concatenation
# - Reciprocal Rank Fusion (RRF)
# - Weighted fusion (sub-query importance)
# Medir: Precision + Recall
```

### 4. Parallel vs Sequential Retrieval
```python
# Parallel: Executar todas buscas simultaneamente
# Sequential: Uma por vez
# Medir: LatÃªncia (parallel deve ser ~40% mais rÃ¡pido)
```

---

## ğŸ’» Estrutura de CÃ³digo

```python
# subquery.py

import asyncio
from typing import List

class SubQueryRAG:
    """
    RAG com decomposiÃ§Ã£o de queries complexas.

    Pipeline:
    1. DecomposiÃ§Ã£o em sub-queries
    2. Retrieval paralelo para cada sub-query
    3. FusÃ£o de resultados (RRF)
    4. LLM generation
    """

    def __init__(self, pinecone_index, embeddings, llm):
        self.index = pinecone_index
        self.embeddings = embeddings
        self.llm = llm
        self.k_per_subquery = 5
        self.max_subqueries = 4

    def decompose(self, query: str) -> List[str]:
        """
        DecompÃµe query complexa em sub-queries.
        """
        prompt = f"""
VocÃª Ã© um assistente que decompÃµe queries complexas.

Query original: "{query}"

Decomponha esta query em 2-4 sub-queries SIMPLES e FOCADAS.
Cada sub-query deve buscar um aspecto especÃ­fico da informaÃ§Ã£o.

Regras:
- MÃ¡ximo 4 sub-queries
- Cada uma deve ser independente
- Cobrir todos aspectos da query original
- Se query Ã© simples, retorne apenas 1 (a original)

Retorne apenas as sub-queries, uma por linha, sem numeraÃ§Ã£o:
"""
        response = self.llm.invoke(prompt, temperature=0.0)

        # Parse sub-queries (separadas por linha)
        sub_queries = [
            sq.strip()
            for sq in response.content.split('\n')
            if sq.strip() and not sq.strip().startswith('#')
        ]

        # Limitar mÃ¡ximo
        return sub_queries[:self.max_subqueries]

    async def retrieve_single(self, sub_query: str) -> List[Document]:
        """
        Busca para uma Ãºnica sub-query.
        """
        query_vector = self.embeddings.embed_query(sub_query)

        results = self.index.query(
            vector=query_vector,
            top_k=self.k_per_subquery,
            include_metadata=True
        )

        chunks = self._parse_results(results)

        # Adicionar metadata de qual sub-query recuperou
        for chunk in chunks:
            chunk.metadata['source_subquery'] = sub_query

        return chunks

    async def retrieve_parallel(self, sub_queries: List[str]) -> List[Document]:
        """
        Retrieval paralelo para todas sub-queries.
        """
        # Executar todas buscas em paralelo
        tasks = [self.retrieve_single(sq) for sq in sub_queries]
        results = await asyncio.gather(*tasks)

        # Combinar todos chunks
        all_chunks = []
        for chunks in results:
            all_chunks.extend(chunks)

        return all_chunks

    def deduplicate(self, chunks: List[Document]) -> List[Document]:
        """
        Remove chunks duplicados (mesmo conteÃºdo).
        """
        seen = set()
        unique_chunks = []

        for chunk in chunks:
            content_hash = hash(chunk.page_content)
            if content_hash not in seen:
                seen.add(content_hash)
                unique_chunks.append(chunk)

        return unique_chunks

    def reciprocal_rank_fusion(
        self,
        chunks: List[Document],
        k: int = 60
    ) -> List[Document]:
        """
        FusÃ£o usando Reciprocal Rank Fusion.

        RRF score = Î£ 1/(k + rank_in_subquery_i)
        """
        # Agrupar chunks por sub-query fonte
        subquery_rankings = {}
        for chunk in chunks:
            sq = chunk.metadata.get('source_subquery', 'unknown')
            if sq not in subquery_rankings:
                subquery_rankings[sq] = []
            subquery_rankings[sq].append(chunk)

        # Calcular RRF score para cada chunk
        rrf_scores = {}
        for chunk in chunks:
            score = 0.0
            for sq, ranked_chunks in subquery_rankings.items():
                # Encontrar rank deste chunk nesta sub-query
                try:
                    rank = ranked_chunks.index(chunk)
                    score += 1.0 / (k + rank)
                except ValueError:
                    # Chunk nÃ£o veio desta sub-query
                    pass

            rrf_scores[id(chunk)] = score
            chunk.metadata['rrf_score'] = score

        # Reordenar por RRF score
        sorted_chunks = sorted(
            chunks,
            key=lambda x: rrf_scores[id(x)],
            reverse=True
        )

        return sorted_chunks

    def generate(self, query: str, context: List[Document]) -> str:
        """
        GeraÃ§Ã£o com LLM.
        """
        prompt = self._build_prompt(query, context)
        response = self.llm.invoke(prompt, temperature=0.0)
        return response.content

    def query(self, query: str) -> dict:
        """
        Pipeline completo.
        """
        start_time = time.time()

        # 1. DecomposiÃ§Ã£o
        t1 = time.time()
        sub_queries = self.decompose(query)
        decompose_time = time.time() - t1

        # 2. Retrieval paralelo
        t2 = time.time()
        all_chunks = asyncio.run(self.retrieve_parallel(sub_queries))
        retrieval_time = time.time() - t2

        # 3. DeduplicaÃ§Ã£o
        unique_chunks = self.deduplicate(all_chunks)

        # 4. FusÃ£o (RRF)
        t3 = time.time()
        fused_chunks = self.reciprocal_rank_fusion(unique_chunks)
        fusion_time = time.time() - t3

        # Selecionar top-10 finais
        final_chunks = fused_chunks[:10]

        # 5. GeraÃ§Ã£o
        t4 = time.time()
        response = self.generate(query, final_chunks)
        generation_time = time.time() - t4

        total_latency = time.time() - start_time

        return {
            "response": response,
            "chunks": final_chunks,
            "sub_queries": sub_queries,
            "metrics": {
                "latency_total": total_latency,
                "latency_decompose": decompose_time,
                "latency_retrieval": retrieval_time,
                "latency_fusion": fusion_time,
                "latency_generation": generation_time,
                "num_subqueries": len(sub_queries),
                "chunks_total": len(all_chunks),
                "chunks_unique": len(unique_chunks),
                "chunks_final": len(final_chunks),
                "technique": "subquery"
            }
        }
```

---

## ğŸ“ VariaÃ§Ãµes AvanÃ§adas

### 1. Adaptive Sub-Query
```python
def adaptive_subquery(query):
    """
    Decide automaticamente se decompor ou nÃ£o.
    """
    # Classificar complexidade
    complexity = classify_complexity(query)

    if complexity == "simple":
        return baseline_rag(query)
    elif complexity == "medium":
        return subquery_rag(query, max_subqueries=2)
    else:  # complex
        return subquery_rag(query, max_subqueries=4)
```

---

### 2. Hierarchical Sub-Query
```python
def hierarchical_subquery(query):
    """
    Sub-queries podem gerar sub-sub-queries.
    """
    # NÃ­vel 1
    sub_queries_l1 = decompose(query)

    # NÃ­vel 2 (apenas para sub-queries complexas)
    all_subqueries = []
    for sq in sub_queries_l1:
        if is_complex(sq):
            sub_queries_l2 = decompose(sq)
            all_subqueries.extend(sub_queries_l2)
        else:
            all_subqueries.append(sq)

    # Retrieval
    chunks = retrieve_parallel(all_subqueries)
    return chunks
```

---

### 3. Sub-Query + Reranking
```python
def subquery_with_reranking(query):
    """
    Combina recall de sub-query com precision de reranking.
    """
    # 1. Sub-query retrieval (alto recall)
    sub_queries = decompose(query)
    chunks = retrieve_parallel(sub_queries, k=10)  # 3Ã—10=30 chunks

    # 2. Deduplica
    unique = deduplicate(chunks)  # ~20 chunks

    # 3. Reranking (alta precision)
    final = rerank(query, unique, k=5)  # Top-5

    return final
```

**BenefÃ­cio**: Recall 0.90 + Precision 0.95 = Best of both worlds

---

## ğŸ“š ReferÃªncias

**Papers:**
- Khattab et al. (2022) - "Demonstrate-Search-Predict: Composing retrieval and language models"
- Press et al. (2023) - "Measuring and Narrowing the Compositionality Gap in Language Models"

**ImplementaÃ§Ãµes:**
- LangChain: `MultiQueryRetriever`
- LlamaIndex: `SubQuestionQueryEngine`

**Benchmarks:**
- HotpotQA (multi-hop): +25% EM vs single query
- 2WikiMultihopQA: +18% F1

---

## ğŸ¯ Aprendizados Chave

1. **Recall Ã© Rei**: Sub-Query maximiza recall em queries complexas
2. **DecomposiÃ§Ã£o = CrÃ­tico**: Qualidade das sub-queries define sucesso
3. **Paralelo Essential**: Retrieval paralelo reduz latÃªncia em 50%
4. **FusÃ£o Matters**: RRF combina rankings de forma justa
5. **Combina com Reranking**: Recall (Sub-Query) + Precision (Reranking) = perfeito

---

## ğŸ“ˆ ProgressÃ£o de Complexidade

```
Baseline RAG (single query)
    â†“
Sub-Query (vocÃª estÃ¡ aqui)
    â†“
    â”œâ”€â†’ Adaptive Sub-Query (auto-decide)
    â”œâ”€â†’ Hierarchical (sub-sub-queries)
    â””â”€â†’ Sub-Query + Reranking (combo perfeito)
```

---

**TÃ©cnica Anterior**: [Reranking](./RERANKING.md)
**PrÃ³xima TÃ©cnica**: [Fusion](./FUSION.md)
