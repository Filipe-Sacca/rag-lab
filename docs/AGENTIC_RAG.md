# Agentic RAG - RAG como Ferramenta de um Agente Inteligente

## ğŸ“‹ DefiniÃ§Ã£o

**Agentic RAG** transforma RAG de um **pipeline fixo** em uma **ferramenta opcional** que um agente de IA pode **decidir usar ou nÃ£o**, junto com outras ferramentas (web search, calculator, APIs).

O agente usa **raciocÃ­nio ReAct** (Reasoning and Acting) para determinar:
- **SE** precisa fazer RAG
- **QUANDO** fazer RAG
- **COMO** formular a query para RAG
- **COMBINAR** RAG com outras ferramentas

**Insight**: Nem toda pergunta precisa de RAG. Um agente inteligente sabe quando usar cada ferramenta.

---

## ğŸ”„ Como Funciona

### Pipeline Completo

```
1. USER QUERY
   â”œâ”€ Query: "Qual o preÃ§o da aÃ§Ã£o da Apple hoje e como isso se compara ao lucro do Ãºltimo trimestre da nossa empresa?"

2. AGENT REASONING (ReAct Loop)
   â”œâ”€ Thought 1: "Preciso de 2 informaÃ§Ãµes:"
   â”‚  â”œâ”€ PreÃ§o aÃ§Ã£o Apple (tempo real, externa)
   â”‚  â””â”€ Lucro nossa empresa (interna, documentos)
   â”‚
   â”œâ”€ Action 1: tool_web_search["preÃ§o aÃ§Ã£o Apple hoje"]
   â”œâ”€ Observation 1: "$185.50 (fechamento hoje)"
   â”‚
   â”œâ”€ Thought 2: "Agora preciso do lucro interno"
   â”œâ”€ Action 2: tool_internal_rag["lucro Ãºltimo trimestre"]
   â”œâ”€ Observation 2: "Lucro Q3: R$ 3 bilhÃµes"
   â”‚
   â”œâ”€ Thought 3: "Tenho todas informaÃ§Ãµes, posso responder"
   â””â”€ Final Answer: "Apple: $185.50. Nosso lucro Q3: R$ 3bi..."

3. RESPONSE
   â””â”€ Resposta sintetizada de mÃºltiplas fontes
```

### ComparaÃ§Ã£o Visual

**RAG Tradicional (Pipeline Fixo):**
```
Query â†’ SEMPRE faz RAG â†’ LLM â†’ Resposta
                â†“
        Mesmo se nÃ£o precisar
```

**Agentic RAG (DecisÃ£o Inteligente):**
```
Query â†’ Agent analisa
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“             â†“          â†“          â†“
  RAG?      Web Search?  Calculator? Direct Answer?
    â†“             â†“          â†“          â†“
  Usa ferramentas APENAS quando necessÃ¡rio
    â†“
  Combina resultados â†’ Resposta
```

---

## ğŸ’¡ Por Que Funciona?

### Problema do RAG Fixo

```python
# Pipeline RAG tradicional:

def rag_pipeline(query):
    chunks = vector_search(query)  # SEMPRE executa
    response = llm.generate(query, chunks)
    return response

# Problemas:

Query 1: "Qual o telefone da empresa?"
â†’ Busca no Vector DB (necessÃ¡rio) âœ…
â†’ Retorna: "(11) 1234-5678"

Query 2: "Quanto Ã© 2 + 2?"
â†’ Busca no Vector DB (desnecessÃ¡rio!) âŒ
â†’ Retorna chunks irrelevantes sobre matemÃ¡tica
â†’ LLM responde "4" (mas gastou busca Ã  toa)

Query 3: "PreÃ§o da aÃ§Ã£o da Apple hoje?"
â†’ Busca no Vector DB (dados internos) âŒ
â†’ NÃ£o acha (dados externos/tempo real)
â†’ LLM: "NÃ£o tenho essa informaÃ§Ã£o"

âŒ RAG fixo = burro
```

### SoluÃ§Ã£o Agentic RAG

```python
# Agent com mÃºltiplas ferramentas:

tools = {
    "internal_rag": buscar_documentos_internos,
    "web_search": buscar_na_internet,
    "calculator": fazer_calculos,
    "sql_query": consultar_banco_dados
}

# Agent decide:

Query 1: "Qual o telefone?"
â†’ Thought: "Info interna, usar RAG"
â†’ Action: internal_rag["telefone"]
âœ… Escolha correta

Query 2: "Quanto Ã© 2 + 2?"
â†’ Thought: "CÃ¡lculo simples, nÃ£o precisa RAG"
â†’ Action: calculator["2+2"]
âœ… Sem desperdÃ­cio

Query 3: "PreÃ§o aÃ§Ã£o Apple hoje?"
â†’ Thought: "Dado externo e atual, preciso web"
â†’ Action: web_search["Apple stock price today"]
âœ… Fonte correta

Query 4: "PreÃ§o aÃ§Ã£o Apple vs nosso lucro?"
â†’ Thought: "Preciso combinar web + RAG"
â†’ Action 1: web_search["Apple price"]
â†’ Action 2: internal_rag["nosso lucro"]
â†’ Final Answer: Sintetiza ambos
âœ… Multi-tool reasoning
```

---

## ğŸ”¬ Exemplo PrÃ¡tico Detalhado

### Caso 1: Query que NÃƒO Precisa de RAG

**Query:**
```
"Quantos dias Ãºteis tem entre 15/nov e 30/nov?"
```

**RAG Tradicional (DesperdÃ­cio):**
```python
# 1. Busca no Vector DB
chunks = search("dias Ãºteis novembro")
# Retorna: PolÃ­ticas de fÃ©rias, calendÃ¡rios antigos...

# 2. LLM tenta responder com chunks irrelevantes
response = llm.generate(query, chunks)
# "Com base nos documentos... [tenta adivinhar]"

âŒ Custo: 1 busca vetorial + chunks irrelevantes
âŒ PrecisÃ£o: Baixa (LLM inventando)
```

**Agentic RAG (Inteligente):**
```python
# Agent ReAct Loop:

Thought: "Esta Ã© uma pergunta de cÃ¡lculo de data.
          NÃ£o preciso de documentos internos.
          Posso calcular diretamente."

Action: calculator["count_business_days(2024-11-15, 2024-11-30)"]

Observation: "11 dias Ãºteis"

Final Answer: "Entre 15/nov e 30/nov hÃ¡ 11 dias Ãºteis."

âœ… Custo: Zero RAG, apenas cÃ¡lculo
âœ… PrecisÃ£o: 100%
```

---

### Caso 2: Query Multi-Fonte

**Query:**
```
"Compare o crescimento de receita da nossa empresa com o crescimento da Apple no Ãºltimo ano"
```

**RAG Tradicional (Incompleto):**
```python
# RAG sÃ³ acessa dados internos
chunks = search("crescimento receita Ãºltimo ano")
# Retorna: Nosso crescimento = 15%

response = llm.generate(query, chunks)
# "Nossa receita cresceu 15%. NÃ£o tenho dados da Apple."

âŒ Resposta incompleta
```

**Agentic RAG (Completo):**
```python
# Agent ReAct Loop:

Thought: "Preciso de 2 dados:
          1. Nosso crescimento (interno) â†’ RAG
          2. Crescimento Apple (externo) â†’ Web Search"

Action 1: internal_rag["crescimento receita Ãºltimo ano nossa empresa"]
Observation 1: "Crescimento: 15%"

Thought: "Tenho nosso dado, agora preciso da Apple"

Action 2: web_search["Apple revenue growth last year 2024"]
Observation 2: "Apple revenue grew 8% in fiscal 2024"

Thought: "Tenho ambos, posso comparar"

Final Answer: "Nossa empresa cresceu 15% vs Apple 8%.
               Crescemos quase 2x mais que a Apple no Ãºltimo ano."

âœ… Multi-fonte: RAG + Web Search
âœ… Resposta completa e comparativa
```

---

### Caso 3: Query que Precisa Apenas de RAG

**Query:**
```
"Qual foi o investimento em P&D no Q3?"
```

**Agentic RAG:**
```python
Thought: "Dado interno especÃ­fico.
          NÃ£o Ã© cÃ¡lculo, nÃ£o Ã© dado externo.
          Preciso usar RAG interno."

Action: internal_rag["investimento P&D Q3"]

Observation: "Investimento P&D Q3: R$ 800 milhÃµes"

Final Answer: "O investimento em P&D no Q3 foi R$ 800 milhÃµes."

âœ… Usa RAG quando apropriado
âœ… NÃ£o tenta outras ferramentas desnecessariamente
```

---

## âš™ï¸ ConfiguraÃ§Ã£o PadrÃ£o

| ParÃ¢metro | Valor | Justificativa |
|-----------|-------|---------------|
| **Agent Type** | ReAct (Reasoning + Acting) | Explica raciocÃ­nio |
| **Max Iterations** | 5-10 | Evita loops infinitos |
| **Tool Timeout** | 30s por ferramenta | Evita travamentos |
| **LLM (Agent Brain)** | GPT-4 / Gemini Pro | Precisa raciocÃ­nio forte |
| **Tool LLM** | GPT-3.5 / Gemini Flash | Ferramentas podem usar modelo menor |

### Ferramentas Comuns

| Ferramenta | DescriÃ§Ã£o | Quando Usar |
|------------|-----------|-------------|
| **internal_rag** | Busca documentos internos | Dados da empresa |
| **web_search** | Google/Bing search | Dados pÃºblicos/atuais |
| **calculator** | OperaÃ§Ãµes matemÃ¡ticas | CÃ¡lculos, datas |
| **sql_query** | Query banco de dados | Dados estruturados |
| **api_call** | Chamar APIs externas | IntegraÃ§Ã£o sistemas |
| **python_repl** | Executar cÃ³digo Python | AnÃ¡lise de dados |

---

## âœ… Vantagens

### 1. EficiÃªncia Massiva
```
RAG Tradicional: 100% queries fazem busca vetorial
Agentic RAG: ~40% queries fazem busca

Economia: 60% nas chamadas ao Vector DB
```

### 2. Multi-Fonte Nativo
```
âœ… Combina RAG + Web Search + APIs
âœ… Responde queries impossÃ­veis para RAG fixo
âœ… Dados internos + externos integrados
```

### 3. Custo-Efetivo
```
Query: "Quanto Ã© 10% de 1000?"

RAG Fixo:
- Busca vetorial: $0.0001
- LLM com chunks: $0.002
Total: $0.0021

Agentic:
- Calculator direto: $0
- LLM agent reasoning: $0.0005
Total: $0.0005 (76% economia)
```

### 4. RaciocÃ­nio ExplÃ­cito
```
Agent mostra COMO chegou na resposta:

Thought: "Preciso de dados externos"
Action: web_search[...]
Observation: [resultado]
Final Answer: [resposta]

âœ… TransparÃªncia
âœ… DebuggÃ¡vel
âœ… UsuÃ¡rio entende processo
```

### 5. Falha Mais Graceful
```
RAG Fixo: NÃ£o acha no Vector DB â†’ "NÃ£o sei"

Agentic: NÃ£o acha no RAG â†’ Tenta web_search
        â†’ Tenta outra fonte
        â†’ MÃºltiplas tentativas antes de desistir
```

### 6. EscalÃ¡vel em Ferramentas
```python
# Adicionar nova ferramenta = trivial:
agent.tools.append({
    "name": "weather_api",
    "description": "Get current weather",
    "function": get_weather
})

# Agent aprende a usar automaticamente
```

---

## âŒ Desvantagens

### 1. LatÃªncia VariÃ¡vel e ImprevisÃ­vel
```
Query simples: "Telefone?"
â†’ Agent: 1 iteration â†’ 2s

Query complexa: "Compare dados A, B, C"
â†’ Agent: 5 iterations â†’ 15s (!)

âŒ LatÃªncia imprevisÃ­vel (1-20s)
âŒ Dificulta SLA
```

### 2. Custo LLM Maior
```
RAG Fixo:
- 1 chamada LLM (geraÃ§Ã£o)

Agentic RAG:
- 1 chamada (reasoning)
- 1 chamada (action planning)
- 1 chamada (synthesis)
- ...potencialmente 5-10 chamadas LLM

Custo: 3-10x maior por query complexa
```

### 3. Risco de Loops e Errors
```python
# Agent pode entrar em loop:

Thought: "Preciso de dado X"
Action: web_search[X]
Observation: "NÃ£o encontrado"

Thought: "Vou tentar de novo"
Action: web_search[X]  # Mesmo que antes!
Observation: "NÃ£o encontrado"

# Repete 10x atÃ© timeout
âŒ DesperdiÃ§a tempo e custo
```

### 4. DependÃªncia de Qualidade do LLM
```
LLM fraco (GPT-3.5):
â†’ RaciocÃ­nio ruim
â†’ Escolhe ferramenta errada
â†’ Loops frequentes

LLM forte (GPT-4):
â†’ RaciocÃ­nio bom
â†’ Escolhas corretas
â†’ Mas 10x mais caro

âŒ Trade-off qualidade vs custo
```

### 5. Complexidade de Debug
```
RAG Fixo: Query â†’ Chunks â†’ Resposta
         â†“ FÃ¡cil debugar

Agentic: Query â†’
         â†“ Thought 1 â†’ Action 1 â†’ Obs 1
         â†“ Thought 2 â†’ Action 2 â†’ Obs 2
         â†“ Thought 3 â†’ Action 3 â†’ Obs 3
         â†“ Final Answer

âŒ DifÃ­cil rastrear ONDE falhou
âŒ Muitos pontos de falha
```

### 6. NÃ£o Garante Uso de RAG
```
Query: "PolÃ­tica de fÃ©rias"

Agent (erroneamente):
Thought: "Posso responder do meu conhecimento"
Final Answer: [Inventa polÃ­tica genÃ©rica]

âŒ Deveria ter usado RAG
âŒ Agent "pulou" ferramenta necessÃ¡ria
```

---

## ğŸ“Š MÃ©tricas Esperadas

### ComparaÃ§Ã£o RAG Fixo vs Agentic

| MÃ©trica | RAG Fixo | Agentic RAG | Î” |
|---------|----------|-------------|---|
| **Success Rate** | 70-80% | 85-95% | +15-20% |
| **Multi-Source Queries** | 0% | 90%+ | N/A |
| **Avg Latency** | 2s (fixo) | 2-8s (variÃ¡vel) | -3x |
| **Avg Custo/Query** | $0.002 | $0.005-0.015 | 3-7x |
| **RAG Usage Rate** | 100% | 30-50% | -50% |

### RAGAS Scores (Queries Apropriadas)

| MÃ©trica | RAG Fixo | Agentic | Î” |
|---------|----------|---------|---|
| **Faithfulness** | 0.80 | 0.90 | +12% |
| **Answer Relevancy** | 0.75 | 0.92 | +23% |
| **Tool Selection Accuracy** | N/A | 0.88 | - |

---

## ğŸ¯ Quando Usar Agentic RAG

### âœ… Casos Ideais

**1. Queries Diversas e ImprevisÃ­veis**
```
âœ… Chatbot geral (nÃ£o sabe tipo de pergunta)
âœ… Assistente executivo (dados internos + externos)
âœ… Research assistant (mÃºltiplas fontes)
```

**2. Multi-DomÃ­nio**
```
âœ… "PreÃ§o aÃ§Ã£o Apple" (web) + "Nosso lucro" (RAG) + "Comparar" (calculator)
âœ… Dados internos + externos + cÃ¡lculos
```

**3. Baixo Volume, Alta Complexidade**
```
âœ… <1K queries/dia
âœ… Cada query vale muito (decisÃµes executivas)
âœ… Budget OK com $5-10/dia
```

**4. Necessidade de Rastreabilidade**
```
âœ… Compliance, audit (precisa ver raciocÃ­nio)
âœ… TransparÃªncia em decisÃµes
âœ… Debugging de respostas
```

**5. IntegraÃ§Ã£o com MÃºltiplos Sistemas**
```
âœ… RAG + CRM + ERP + Web
âœ… OrquestraÃ§Ã£o de ferramentas
```

---

### âŒ Quando NÃƒO Usar

**1. Queries PrevisÃ­veis e HomogÃªneas**
```
âŒ FAQ system (sempre usa RAG)
âŒ DocumentaÃ§Ã£o tÃ©cnica (sempre RAG)
â†’ RAG fixo Ã© suficiente e mais rÃ¡pido
```

**2. LatÃªncia CrÃ­tica**
```
âŒ SLA <2s
âŒ Real-time chat
âŒ Autocomplete
â†’ Agentic = imprevisÃ­vel (1-15s)
```

**3. Alto Volume de Queries**
```
âŒ >10K queries/dia
âŒ Custo 5x RAG fixo = $50+/dia
â†’ InviÃ¡vel economicamente
```

**4. LLM Fraco DisponÃ­vel**
```
âŒ SÃ³ tem acesso a GPT-3.5 ou modelos locais fracos
â†’ RaciocÃ­nio ruim = agent inÃºtil
```

**5. Requisito de Determinismo**
```
âŒ Precisa garantir sempre usa RAG
âŒ NÃ£o pode "pular" busca interna
â†’ RAG fixo = previsÃ­vel
```

---

## ğŸ”¬ Experimentos Recomendados

### 1. Tool Usage Analysis
```python
# Medir: Quais ferramentas sÃ£o usadas com que frequÃªncia
# Dataset: 1000 queries diversas
# MÃ©trica: % uso de cada tool
# Insight: Otimizar tools mais usados
```

### 2. LLM Model Comparison
```python
# Testar: GPT-4, GPT-3.5, Gemini Pro, Claude
# Medir: Tool selection accuracy, cost, latency
# HipÃ³tese: GPT-4 melhor mas 10x mais caro
```

### 3. Max Iterations Impact
```python
# Testar: max_iter = 3, 5, 10, 20
# Medir: Success rate vs latency
# HipÃ³tese: 5-7 iterations = sweet spot
```

---

## ğŸ’» Estrutura de CÃ³digo (LangGraph)

```python
# agentic_rag.py

from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator

class AgentState(TypedDict):
    """Estado do agente durante execuÃ§Ã£o"""
    query: str
    thoughts: Annotated[list, operator.add]
    actions: Annotated[list, operator.add]
    observations: Annotated[list, operator.add]
    final_answer: str
    iterations: int

# Definir ferramentas
def internal_rag(query: str) -> str:
    """Busca documentos internos"""
    chunks = vector_search(query)
    return f"Chunks encontrados: {chunks}"

def web_search(query: str) -> str:
    """Busca na web"""
    results = google_search(query)
    return f"Resultados: {results}"

def calculator(expression: str) -> str:
    """Calcula expressÃ£o matemÃ¡tica"""
    result = eval(expression)
    return f"Resultado: {result}"

tools = {
    "internal_rag": internal_rag,
    "web_search": web_search,
    "calculator": calculator
}

# NÃ³s do grafo
def reasoning_node(state: AgentState) -> AgentState:
    """Agent pensa sobre prÃ³ximo passo"""

    prompt = f"""
VocÃª Ã© um agente inteligente com as seguintes ferramentas:
{list(tools.keys())}

Query do usuÃ¡rio: {state['query']}

HistÃ³rico:
Thoughts: {state['thoughts']}
Actions: {state['actions']}
Observations: {state['observations']}

PrÃ³ximo passo:
1. Se vocÃª tem informaÃ§Ã£o suficiente â†’ Final Answer: [resposta]
2. Caso contrÃ¡rio â†’ Thought: [raciocÃ­nio] | Action: tool_name[input]

Formato: Thought: ... | Action: ... OU Final Answer: ...
"""

    response = llm.invoke(prompt)

    if "Final Answer:" in response:
        state["final_answer"] = response.split("Final Answer:")[1].strip()
    else:
        thought, action = response.split("|")
        state["thoughts"].append(thought.strip())
        state["actions"].append(action.strip())

    state["iterations"] += 1
    return state

def action_node(state: AgentState) -> AgentState:
    """Executa aÃ§Ã£o escolhida pelo agent"""

    if not state["actions"]:
        return state

    last_action = state["actions"][-1]

    # Parse: "Action: tool_name[input]"
    tool_name = last_action.split("[")[0].split(":")[-1].strip()
    tool_input = last_action.split("[")[1].split("]")[0]

    # Executar ferramenta
    if tool_name in tools:
        observation = tools[tool_name](tool_input)
        state["observations"].append(observation)
    else:
        state["observations"].append(f"Erro: Tool {tool_name} nÃ£o existe")

    return state

def should_continue(state: AgentState) -> str:
    """Decide se continua ou termina"""

    if state["final_answer"]:
        return "end"

    if state["iterations"] >= 10:
        return "end"  # Max iterations

    return "continue"

# Construir grafo
workflow = StateGraph(AgentState)

# Adicionar nÃ³s
workflow.add_node("reasoning", reasoning_node)
workflow.add_node("action", action_node)

# Adicionar arestas
workflow.set_entry_point("reasoning")
workflow.add_edge("reasoning", "action")
workflow.add_conditional_edges(
    "action",
    should_continue,
    {
        "continue": "reasoning",
        "end": END
    }
)

# Compilar
agent = workflow.compile()

# Executar
def query_agentic_rag(query: str) -> dict:
    """
    Executa Agentic RAG completo.
    """
    start_time = time.time()

    initial_state = {
        "query": query,
        "thoughts": [],
        "actions": [],
        "observations": [],
        "final_answer": "",
        "iterations": 0
    }

    # Executar grafo
    final_state = agent.invoke(initial_state)

    latency = time.time() - start_time

    return {
        "response": final_state["final_answer"],
        "reasoning_trace": {
            "thoughts": final_state["thoughts"],
            "actions": final_state["actions"],
            "observations": final_state["observations"]
        },
        "metrics": {
            "latency": latency,
            "iterations": final_state["iterations"],
            "tools_used": len(final_state["actions"]),
            "technique": "agentic_rag"
        }
    }
```

---

## ğŸ“š ReferÃªncias

**Papers:**
- Yao et al. (2023) - "ReAct: Synergizing Reasoning and Acting in Language Models"
- Shinn et al. (2023) - "Reflexion: Language Agents with Verbal Reinforcement Learning"

**Frameworks:**
- LangGraph (LangChain) - Graph-based agent orchestration
- AutoGPT - Autonomous agent framework
- AgentGPT - Web-based agent platform

**Benchmarks:**
- ToolBench: Tool selection accuracy
- HotPotQA: Multi-hop reasoning

---

## ğŸ¯ Aprendizados Chave

1. **RAG = Ferramenta, NÃ£o Pipeline**: Agent decide quando usar
2. **Multi-Tool Reasoning**: Combina fontes impossÃ­veis para RAG fixo
3. **Trade-off Custo/Qualidade**: 5x custo para +20% success rate
4. **TransparÃªncia**: ReAct mostra raciocÃ­nio explÃ­cito
5. **Futuro do RAG**: Agentic Ã© evoluÃ§Ã£o natural, mas nÃ£o substitui RAG fixo totalmente

---

**TÃ©cnica Anterior**: [Parent Document](./PARENT_DOCUMENT.md)
**PrÃ³xima TÃ©cnica**: [Adaptive RAG](./ADAPTIVE_RAG.md)
