# Adaptive RAG - Sele√ß√£o Autom√°tica da Melhor T√©cnica

## üìã Defini√ß√£o

**Adaptive RAG** √© um sistema que **analisa automaticamente cada query** e **seleciona dinamicamente a melhor t√©cnica RAG** (ou combina√ß√£o de t√©cnicas) para aquela query espec√≠fica.

Ao inv√©s de usar sempre a mesma t√©cnica, o sistema adapta sua estrat√©gia baseado em:
- Complexidade da query
- Tipo de informa√ß√£o necess√°ria
- Requisitos de lat√™ncia/custo
- Caracter√≠sticas do dom√≠nio

**Insight**: N√£o existe "melhor t√©cnica RAG universal". A melhor t√©cnica depende da query.

---

## üîÑ Como Funciona

### Pipeline Completo

```
1. QUERY ANALYSIS (Classifica√ß√£o)
   ‚îú‚îÄ Query: "Qual o telefone da empresa?"
   ‚îú‚îÄ LLM analisa caracter√≠sticas:
   ‚îÇ  ‚îú‚îÄ Complexidade: Simples
   ‚îÇ  ‚îú‚îÄ Tipo: Factual lookup
   ‚îÇ  ‚îú‚îÄ Multi-hop: N√£o
   ‚îÇ  ‚îú‚îÄ Necessita contexto: M√≠nimo
   ‚îÇ  ‚îî‚îÄ Fontes: Interna √∫nica
   ‚îî‚îÄ Classifica√ß√£o: "simple_lookup"

2. TECHNIQUE SELECTION (Decis√£o)
   ‚îú‚îÄ Baseado em classifica√ß√£o:
   ‚îÇ  ‚îî‚îÄ simple_lookup ‚Üí Baseline RAG
   ‚îú‚îÄ Routing rules:
   ‚îÇ  ‚îú‚îÄ simple ‚Üí Baseline
   ‚îÇ  ‚îú‚îÄ complex_multi_hop ‚Üí Sub-Query + Reranking
   ‚îÇ  ‚îú‚îÄ ambiguous ‚Üí HyDE + Reranking
   ‚îÇ  ‚îú‚îÄ relational ‚Üí Graph RAG
   ‚îÇ  ‚îî‚îÄ maximum_quality ‚Üí Fusion
   ‚îî‚îÄ T√©cnica selecionada: Baseline RAG

3. EXECUTION
   ‚îú‚îÄ Executa t√©cnica escolhida
   ‚îî‚îÄ Retorna resposta

4. FEEDBACK LOOP (Opcional)
   ‚îú‚îÄ Avalia qualidade da resposta
   ‚îú‚îÄ Se ruim: Tenta t√©cnica mais sofisticada
   ‚îî‚îÄ Aprende com resultados (ML)
```

### Compara√ß√£o Visual

**RAG Fixo:**
```
Todas queries ‚Üí Baseline RAG ‚Üí Resposta
```

**Adaptive RAG:**
```
Query ‚Üí An√°lise
          ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì           ‚Üì      ‚Üì        ‚Üì         ‚Üì
 Simples    Complexa Amb√≠gua Relacional Multi-fonte
    ‚Üì           ‚Üì      ‚Üì        ‚Üì         ‚Üì
 Baseline   Sub-Query HyDE  Graph RAG   Fusion
    ‚Üì           ‚Üì      ‚Üì        ‚Üì         ‚Üì
         Resposta otimizada por tipo
```

---

## üí° Por Que Funciona?

### Problema: One-Size-Fits-All

```python
# Usando sempre Fusion (t√©cnica mais avan√ßada):

Query 1: "Qual o telefone?"
‚Üí Fusion: 4 query variations + semantic + BM25
‚Üí Lat√™ncia: 5s
‚Üí Custo: $0.015
‚Üí Resultado: Telefone correto
‚ùå Baseline daria mesmo resultado em 1s por $0.001

Query 2: "Compare crescimento A vs B nos √∫ltimos 3 anos"
‚Üí Fusion: M√∫ltiplas estrat√©gias, m√°xima cobertura
‚Üí Lat√™ncia: 6s
‚Üí Custo: $0.020
‚Üí Resultado: An√°lise completa
‚úÖ Fusion necess√°rio, Baseline falharia

# Usando sempre Fusion = desperd√≠cio 80% do tempo
```

### Solu√ß√£o: Adaptive RAG

```python
# Sistema adaptativo:

Query 1: "Qual o telefone?"
‚Üí An√°lise: Simple lookup
‚Üí Escolhe: Baseline (r√°pido, barato)
‚Üí Lat√™ncia: 1s, Custo: $0.001
‚úÖ Resultado correto com efici√™ncia m√°xima

Query 2: "Compare crescimento A vs B nos √∫ltimos 3 anos"
‚Üí An√°lise: Complex multi-hop comparative
‚Üí Escolhe: Sub-Query + Reranking
‚Üí Lat√™ncia: 3s, Custo: $0.008
‚úÖ Resultado completo com t√©cnica apropriada

# Economia: 60-80% custo, 40-60% lat√™ncia
# Sem perder qualidade
```

---

## üî¨ Exemplo Pr√°tico Detalhado

### Caso 1: Query Simples

**Query:**
```
"Endere√ßo da matriz"
```

**An√°lise:**
```python
classifier = QueryClassifier()
features = classifier.analyze("Endere√ßo da matriz")

{
  "complexity": "simple",
  "query_type": "factual_lookup",
  "entities": ["matriz"],
  "multi_hop": false,
  "requires_reasoning": false,
  "ambiguity_score": 0.1,
  "expected_answer_length": "short"
}
```

**Decis√£o:**
```python
# Routing rules:
if features["complexity"] == "simple" and not features["multi_hop"]:
    technique = "baseline"

# Execu√ß√£o:
response = baseline_rag("Endere√ßo da matriz")
# Lat√™ncia: 1.2s
# Custo: $0.001
```

---

### Caso 2: Query Amb√≠gua

**Query:**
```
"Como melhorar performance?"
```

**An√°lise:**
```python
{
  "complexity": "medium",
  "query_type": "open_ended",
  "entities": [],
  "multi_hop": false,
  "requires_reasoning": true,
  "ambiguity_score": 0.8,  # Alta ambiguidade!
  "expected_answer_length": "medium"
}
```

**Decis√£o:**
```python
# Routing rules:
if features["ambiguity_score"] > 0.7:
    technique = "hyde"  # HyDE resolve ambiguidade

# Execu√ß√£o:
response = hyde_rag("Como melhorar performance?")
# HyDE gera hip√≥tese espec√≠fica
# Lat√™ncia: 2.5s
# Custo: $0.004
```

---

### Caso 3: Query Multi-Hop Relacional

**Query:**
```
"Quais colegas do CFO trabalharam na mesma empresa anterior que ele?"
```

**An√°lise:**
```python
{
  "complexity": "high",
  "query_type": "relational",
  "entities": ["CFO"],
  "multi_hop": true,  # 2+ n√≠veis de rela√ß√£o
  "requires_reasoning": true,
  "ambiguity_score": 0.3,
  "expected_answer_length": "long"
}
```

**Decis√£o:**
```python
# Routing rules:
if features["query_type"] == "relational" and features["multi_hop"]:
    technique = "graph_rag"  # Grafo resolve multi-hop

# Execu√ß√£o:
response = graph_rag("Quais colegas do CFO...")
# Navega grafo de conhecimento
# Lat√™ncia: 4s
# Custo: $0.005
```

---

### Caso 4: Query Cr√≠tica (M√°xima Qualidade)

**Query:**
```
"An√°lise completa de conformidade legal do produto X"
```

**An√°lise:**
```python
{
  "complexity": "very_high",
  "query_type": "comprehensive_analysis",
  "entities": ["produto X"],
  "multi_hop": true,
  "requires_reasoning": true,
  "ambiguity_score": 0.4,
  "expected_answer_length": "very_long",
  "domain": "legal",  # Dom√≠nio cr√≠tico!
  "quality_requirement": "maximum"
}
```

**Decis√£o:**
```python
# Routing rules:
if features["domain"] == "legal" or features["quality_requirement"] == "maximum":
    technique = "fusion"  # M√°xima qualidade

# Execu√ß√£o:
response = fusion_rag("An√°lise completa conformidade...")
# M√∫ltiplas estrat√©gias, reranking, m√°xima cobertura
# Lat√™ncia: 6s
# Custo: $0.020
# Mas qualidade cr√≠tica justifica
```

---

## ‚öôÔ∏è Configura√ß√£o Padr√£o

| Par√¢metro | Valor | Justificativa |
|-----------|-------|---------------|
| **Classifier** | LLM-based ou ML model | LLM = simples, ML = r√°pido |
| **Fallback Strategy** | Progressive enhancement | Se t√©cnica falha, tenta pr√≥xima |
| **Quality Threshold** | 0.7 | Se qualidade < 0.7, upgrade t√©cnica |
| **Max Technique Attempts** | 3 | Evita loops infinitos |
| **Learning Enabled** | True | Melhora com feedback |

### Routing Rules (Exemplo)

```python
routing_rules = {
    "simple_lookup": {
        "technique": "baseline",
        "conditions": {
            "complexity": "simple",
            "multi_hop": False,
            "ambiguity_score": "<0.3"
        }
    },

    "ambiguous_query": {
        "technique": "hyde",
        "conditions": {
            "ambiguity_score": ">0.7"
        }
    },

    "multi_hop": {
        "technique": "subquery",
        "conditions": {
            "multi_hop": True,
            "complexity": "medium|high"
        }
    },

    "relational": {
        "technique": "graph_rag",
        "conditions": {
            "query_type": "relational",
            "entities": ">1"
        }
    },

    "maximum_quality": {
        "technique": "fusion",
        "conditions": {
            "domain": ["legal", "medical", "financial"],
            "OR": {
                "quality_requirement": "maximum"
            }
        }
    },

    "default": {
        "technique": "baseline",
        "conditions": {}  # Fallback
    }
}
```

---

## ‚úÖ Vantagens

### 1. Efici√™ncia Massiva
```
Economia vs sempre usar t√©cnica mais avan√ßada:
- Lat√™ncia: -50-70% (m√©dia)
- Custo: -60-80% (m√©dia)
- Sem perder qualidade em queries complexas
```

### 2. Qualidade Otimizada por Query
```
Query simples: Baseline (suficiente)
Query complexa: Fusion (necess√°rio)

Resultado: Melhor qualidade m√©dia com menor custo
```

### 3. Melhoria Cont√≠nua
```python
# Feedback loop:
if response_quality < threshold:
    # Tenta t√©cnica mais sofisticada
    upgrade_technique()

# Machine learning:
# Aprende qual t√©cnica funciona melhor para cada tipo
model.train(query_features, best_technique)
```

### 4. Flexibilidade
```
F√°cil adicionar nova t√©cnica:
- Adiciona regra de routing
- Sistema aprende quando usar
- Sem reescrever c√≥digo existente
```

### 5. Transpar√™ncia
```
Sistema explica PORQUE escolheu t√©cnica:

"Query classificada como 'multi-hop relational'
 ‚Üí Usando Graph RAG (melhor para rela√ß√µes)"
```

### 6. Custo-Benef√≠cio √ìtimo
```
80% queries simples ‚Üí Baseline ($0.001)
15% queries m√©dias ‚Üí HyDE/Reranking ($0.004)
5% queries complexas ‚Üí Fusion/Graph ($0.015)

Custo m√©dio: $0.002 (vs $0.015 sempre Fusion)
Economia: 87%!
```

---

## ‚ùå Desvantagens

### 1. Overhead de Classifica√ß√£o
```
Baseline simples: 1.2s
Adaptive: 0.3s (classifica√ß√£o) + 1.2s (execu√ß√£o) = 1.5s

‚ùå Adiciona 0.3s toda query
```

### 2. Complexidade de Manuten√ß√£o
```
# Precisa manter:
- Todas t√©cnicas RAG
- Sistema de classifica√ß√£o
- Routing rules
- Feedback loop
- ML models (opcional)

Complexidade: Alta
```

### 3. Risco de Classifica√ß√£o Errada
```
Query: "Pol√≠tica de trabalho remoto complexa..."

Classifica√ß√£o (errada): Simple lookup
T√©cnica escolhida: Baseline
Resultado: Incompleto

‚ùå Deveria ter usado HyDE ou Sub-Query
```

### 4. Cold Start Problem
```
Primeira execu√ß√£o: Sem dados de feedback
‚Üí Routing rules = heur√≠sticas
‚Üí Pode n√£o ser √≥timo

Ap√≥s 1000 queries: Sistema aprendeu
‚Üí Classifica√ß√£o melhora
‚Üí Mas precisa volume inicial
```

### 5. Custo de Desenvolvimento
```
Implementar Adaptive RAG:
- 2-3 semanas vs 1 semana RAG fixo
- Precisa dataset de queries para treinar
- Testes extensivos de routing rules
```

### 6. Lat√™ncia Imprevis√≠vel
```
Query A: Baseline ‚Üí 1s
Query B: Fusion ‚Üí 6s

‚ùå Dificulta SLA fixo
```

---

## üìä M√©tricas Esperadas

### Compara√ß√£o: Sempre Fusion vs Adaptive

| M√©trica | Sempre Fusion | Adaptive RAG | Œî |
|---------|---------------|--------------|---|
| **Avg Lat√™ncia** | 5.5s | 2.2s | -60% ‚≠ê |
| **Avg Custo/Query** | $0.018 | $0.004 | -78% ‚≠ê |
| **Quality (Simple)** | 0.90 | 0.88 | -2% |
| **Quality (Complex)** | 0.95 | 0.93 | -2% |
| **Overall Quality** | 0.91 | 0.89 | -2% |

**Trade-off**: -2% qualidade para -60% lat√™ncia e -78% custo = √≥timo!

### Distribui√ß√£o de T√©cnicas (Exemplo Real)

```
1000 queries analisadas:

Baseline:     650 queries (65%) - simples, lookup
HyDE:         150 queries (15%) - amb√≠guas
Reranking:     80 queries (8%)  - precis√£o cr√≠tica
Sub-Query:     70 queries (7%)  - multi-hop
Fusion:        30 queries (3%)  - m√°xima qualidade
Graph RAG:     20 queries (2%)  - relacional

Economia vs sempre Fusion:
- 97% das queries usam t√©cnica mais barata
- 3% usam t√©cnica cara (quando necess√°rio)
```

---

## üéØ Quando Usar Adaptive RAG

### ‚úÖ Casos Ideais

**1. Queries Heterog√™neas**
```
‚úÖ Chatbot geral (tipos variados)
‚úÖ Search engine (lookups + an√°lises)
‚úÖ Assistente corporativo (simples + complexo)
```

**2. Budget Limitado com Alta Qualidade Necess√°ria**
```
‚úÖ Startups (economizar 80%)
‚úÖ Alto volume (>10K queries/dia)
‚úÖ Mas n√£o pode sacrificar qualidade totalmente
```

**3. Lat√™ncia Vari√°vel Aceit√°vel**
```
‚úÖ Async workflows (n√£o real-time)
‚úÖ Background jobs
‚úÖ Research assistants
```

**4. Capacidade de Manter M√∫ltiplas T√©cnicas**
```
‚úÖ Time de engenharia dedicado
‚úÖ Infraestrutura robusta
‚úÖ CI/CD para m√∫ltiplos pipelines
```

**5. Volume Suficiente para Aprendizado**
```
‚úÖ >1K queries/dia
‚úÖ Dados para treinar classifier
‚úÖ Feedback loop vi√°vel
```

---

### ‚ùå Quando N√ÉO Usar

**1. Queries Homog√™neas**
```
‚ùå Documenta√ß√£o t√©cnica (sempre mesmo tipo)
‚ùå FAQ system (sempre lookups)
‚Üí Use t√©cnica fixa otimizada
```

**2. Lat√™ncia Cr√≠tica Fixa**
```
‚ùå SLA <2s garantido
‚ùå Real-time chat
‚Üí Adaptive = imprevis√≠vel (1-6s)
```

**3. Equipe Pequena**
```
‚ùå 1-2 devs
‚ùå N√£o pode manter m√∫ltiplas t√©cnicas
‚Üí Use RAG fixo (Baseline ou HyDE)
```

**4. MVP / Prototipagem**
```
‚ùå Precisa validar em 1 semana
‚ùå Complexidade = overhead desnecess√°rio
‚Üí Comece simples, adicione Adaptive depois
```

**5. Baixo Volume**
```
‚ùå <100 queries/dia
‚ùå N√£o justifica complexidade
‚Üí Use t√©cnica fixa de qualidade m√©dia-alta
```

---

## üî¨ Experimentos Recomendados

### 1. Query Classification Accuracy
```python
# Dataset: 1000 queries com t√©cnica √≥tima anotada
# Medir: Precision, Recall de classificador
# Objetivo: >90% accuracy
```

### 2. Cost-Quality Trade-off
```python
# Testar diferentes thresholds para upgrade:
# - Conservative: Usa t√©cnica cara frequentemente
# - Aggressive: Usa t√©cnica barata ao m√°ximo
# Medir: Custo vs RAGAS scores
```

### 3. Fallback Strategy Effectiveness
```python
# Quando t√©cnica escolhida falha:
# - Strategy A: Tenta pr√≥xima t√©cnica
# - Strategy B: Tenta t√©cnica mais avan√ßada
# Medir: Recovery rate
```

---

## üíª Estrutura de C√≥digo

```python
# adaptive_rag.py

from typing import Dict, Callable
import numpy as np

class AdaptiveRAG:
    """
    Sistema adaptativo que seleciona melhor t√©cnica RAG.

    Pipeline:
    1. Classify query
    2. Select technique
    3. Execute
    4. Evaluate & learn
    """

    def __init__(self, techniques: Dict[str, Callable], llm):
        self.techniques = techniques  # {name: function}
        self.llm = llm
        self.classifier = QueryClassifier(llm)
        self.router = TechniqueRouter()
        self.feedback_store = []

    def classify_query(self, query: str) -> Dict:
        """
        Classifica query em features.
        """
        prompt = f"""
Analise esta query e extraia caracter√≠sticas:

Query: "{query}"

Retorne JSON:
{{
  "complexity": "simple" | "medium" | "high" | "very_high",
  "query_type": "factual_lookup" | "analysis" | "relational" | "comparison" | "open_ended",
  "multi_hop": true | false,
  "ambiguity_score": 0.0-1.0,
  "entities_count": number,
  "expected_answer_length": "short" | "medium" | "long"
}}
"""
        response = self.llm.invoke(prompt, temperature=0.0)
        features = json.loads(response.content)
        return features

    def select_technique(self, features: Dict) -> str:
        """
        Seleciona t√©cnica baseado em features.
        """
        # Routing rules
        if features["complexity"] == "simple" and not features["multi_hop"]:
            return "baseline"

        if features["ambiguity_score"] > 0.7:
            return "hyde"

        if features["multi_hop"] and features["entities_count"] > 1:
            if features["query_type"] == "relational":
                return "graph_rag"
            else:
                return "subquery"

        if features["complexity"] == "very_high":
            return "fusion"

        # Reranking para queries de precis√£o m√©dia-alta
        if features["complexity"] in ["medium", "high"]:
            return "reranking"

        # Default
        return "baseline"

    def execute_technique(self, technique: str, query: str) -> Dict:
        """
        Executa t√©cnica selecionada.
        """
        if technique not in self.techniques:
            # Fallback
            technique = "baseline"

        start_time = time.time()
        result = self.techniques[technique](query)
        latency = time.time() - start_time

        return {
            "response": result["response"],
            "technique_used": technique,
            "latency": latency,
            **result.get("metrics", {})
        }

    def evaluate_quality(self, query: str, response: str, chunks: list) -> float:
        """
        Avalia qualidade da resposta (simplificado).
        """
        # Usar RAGAS ou heur√≠stica simples
        prompt = f"""
Avalie a qualidade desta resposta (0.0-1.0):

Query: {query}
Resposta: {response}

Score (0.0-1.0):
"""
        score_response = self.llm.invoke(prompt)
        score = float(score_response.content.strip())
        return score

    def query(self, query: str, quality_threshold: float = 0.7) -> Dict:
        """
        Pipeline completo adaptativo.
        """
        start_time = time.time()

        # 1. Classify
        t1 = time.time()
        features = self.classify_query(query)
        classify_time = time.time() - t1

        # 2. Select technique
        technique = self.select_technique(features)

        # 3. Execute
        t2 = time.time()
        result = self.execute_technique(technique, query)
        execute_time = time.time() - t2

        # 4. Evaluate quality
        quality_score = self.evaluate_quality(
            query,
            result["response"],
            result.get("chunks", [])
        )

        # 5. Fallback se qualidade baixa
        if quality_score < quality_threshold and technique != "fusion":
            # Tenta t√©cnica mais avan√ßada
            upgraded_technique = self._upgrade_technique(technique)

            result = self.execute_technique(upgraded_technique, query)
            quality_score = self.evaluate_quality(
                query,
                result["response"],
                result.get("chunks", [])
            )

            result["technique_used"] = f"{technique} ‚Üí {upgraded_technique} (upgraded)"

        total_latency = time.time() - start_time

        # 6. Store feedback para aprendizado
        self.feedback_store.append({
            "query": query,
            "features": features,
            "technique": result["technique_used"],
            "quality_score": quality_score,
            "latency": total_latency
        })

        return {
            "response": result["response"],
            "technique_used": result["technique_used"],
            "query_features": features,
            "quality_score": quality_score,
            "metrics": {
                "latency_total": total_latency,
                "latency_classify": classify_time,
                "latency_execute": execute_time,
                "technique": "adaptive_rag"
            }
        }

    def _upgrade_technique(self, current: str) -> str:
        """
        Upgrade para t√©cnica mais sofisticada.
        """
        upgrade_path = {
            "baseline": "reranking",
            "hyde": "reranking",
            "reranking": "fusion",
            "subquery": "fusion",
            "graph_rag": "fusion",
            "fusion": "fusion"  # J√° √© o m√°ximo
        }
        return upgrade_path.get(current, "fusion")

    def get_statistics(self) -> Dict:
        """
        Estat√≠sticas de uso de t√©cnicas.
        """
        technique_counts = {}
        total_cost = 0
        total_latency = 0

        for record in self.feedback_store:
            tech = record["technique"]
            technique_counts[tech] = technique_counts.get(tech, 0) + 1
            total_latency += record["latency"]

        return {
            "total_queries": len(self.feedback_store),
            "technique_distribution": technique_counts,
            "avg_latency": total_latency / len(self.feedback_store) if self.feedback_store else 0,
            "avg_quality": np.mean([r["quality_score"] for r in self.feedback_store]) if self.feedback_store else 0
        }
```

---

## üéì Varia√ß√µes Avan√ßadas

### 1. ML-Based Classification
```python
from sklearn.ensemble import RandomForestClassifier

class MLQueryClassifier:
    """
    Classifier treinado com dados hist√≥ricos.
    """
    def __init__(self):
        self.model = RandomForestClassifier()
        self.trained = False

    def train(self, queries, optimal_techniques):
        """
        Treina com queries passadas e t√©cnica √≥tima.
        """
        X = [self.extract_features(q) for q in queries]
        y = optimal_techniques

        self.model.fit(X, y)
        self.trained = True

    def predict(self, query):
        """
        Prediz melhor t√©cnica.
        """
        features = self.extract_features(query)
        technique = self.model.predict([features])[0]
        return technique

    def extract_features(self, query):
        """
        Features num√©ricas para ML.
        """
        return [
            len(query.split()),  # word count
            query.count("?"),    # question marks
            len(set(query.split())),  # unique words
            # ... mais features
        ]
```

### 2. A/B Testing Framework
```python
def adaptive_with_ab_testing(query):
    """
    Testa m√∫ltiplas t√©cnicas, aprende qual melhor.
    """
    if random() < 0.1:  # 10% das queries
        # Teste: Executa 2 t√©cnicas
        technique_a = select_technique(query)
        technique_b = random_alternative(technique_a)

        result_a = execute(technique_a, query)
        result_b = execute(technique_b, query)

        # Usu√°rio escolhe qual melhor (ou RAGAS)
        winner = evaluate_winner(result_a, result_b)

        # Aprende
        update_model(query, winner)

        return result_a  # Retorna padr√£o
    else:
        # Normal: Usa modelo treinado
        return adaptive_rag(query)
```

---

## üìö Refer√™ncias

**Papers:**
- Jeong et al. (2024) - "Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models"
- Asai et al. (2024) - "Self-RAG: Learning to Retrieve, Generate and Critique"

**Implementa√ß√µes:**
- LangChain: Router chains
- LlamaIndex: Query routing

---

## üéØ Aprendizados Chave

1. **Context-Aware RAG**: Melhor t√©cnica depende do contexto
2. **80/20 Rule**: 80% queries = simples (baseline suficiente)
3. **Trade-off Aceit√°vel**: -2% qualidade por -70% custo/lat√™ncia
4. **Melhoria Cont√≠nua**: Sistema aprende com feedback
5. **Production Essential**: Adaptive √© futuro para sistemas em escala

---

**T√©cnica Anterior**: [Agentic RAG](./AGENTIC_RAG.md)
**Resumo Comparativo**: [COMPARISON.md](./COMPARISON.md) *(pr√≥ximo)*
